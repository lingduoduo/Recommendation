{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MHkcIl4E-Fgf"
   },
   "source": [
    "# Tutorial: TF-Ranking for sparse features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8tMYn22vtDV"
   },
   "source": [
    "This tutorial is an end-to-end walkthrough of training a TensorFlow Ranking (TF-Ranking) neural network model which incorporates sparse textual features.\n",
    "\n",
    "A Python script version of this code is available [here](https://github.com/tensorflow/ranking/blob/master/tensorflow_ranking/examples/tf_ranking_tfrecord.py). The script version supports flags for hyperparameters, and advanced use-cases like [Document Interaction Network](https://research.google/pubs/pub49364).\n",
    "\n",
    "TF-Ranking is a library for solving large scale ranking problems using deep learning. TF-Ranking can handle heterogeneous dense and sparse features, and scales up to millions of data points. For more details, please read the technical paper published on [arXiv](https://arxiv.org/abs/1812.00073)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmGZHWkdMEdB"
   },
   "source": [
    "## Motivation\n",
    "\n",
    "Learning to Rank (LTR) deals with learning to optimally order a list of examples, given some context. For instance, in search applications, examples are documents and context is the query.\n",
    "\n",
    "These models are usually trained using user relevance feedback, which can be explicit (human ratings) or implicit (clicks).\n",
    "\n",
    "This tutorial demonstrates how to build ranking estimators over sparse features, such as textual data. Textual data is prevalent in several settings for ranking, and plays a significant role is relevance judgment by a user.\n",
    "\n",
    "In three different LTR scenarios, the following textual features provide useful signals for ranking:\n",
    "\n",
    "*   Search: queries and document titles\n",
    "*   Question Answering: questions and answers\n",
    "*   Recommendation: titles of items and their descriptions\n",
    "\n",
    "Hence it is important for LTR models to effectively incorporate textual features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5A2UcQM1b7S"
   },
   "source": [
    "## Task: Ranking over Question-Answering data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JNilCoqq1jJn"
   },
   "source": [
    "### ANTIQUE: A Question Answering Dataset\n",
    "\n",
    "For the purpose of this tutorial, we consider ranking problem over ANTIQUE, a question-answering dataset. Given a query, and a list of answers, the objective it to maximize a rank related metric (say NDCG).\n",
    "\n",
    "[ANTIQUE](http://hamedz.ir/resources/) is a publicly available dataset for open-domain non-factoid question answering, collected over Yahoo! answers.\n",
    "\n",
    "Each question has a list of answers, whose relevance are graded on a scale of 1-5.\n",
    "\n",
    "The list size can vary depending on the query, so we use a fixed \"list size\" of 50, where the list is either truncated or padded with dummy values.\n",
    "\n",
    "This dataset is a suitable one for learning-to-rank scenario. The dataset is split into 2206 queries for training and 200 queries for testing. For more details, please read the technical paper on [arXiv](https://arxiv.org/abs/1905.08957)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIxFuiy5qh6L"
   },
   "source": [
    "\n",
    "Download training, test data and vocabulary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mwxtsi4wqoOJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-05 14:27:35--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/vocab.txt\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 231508 (226K) [text/plain]\n",
      "Saving to: ‘/tmp/vocab.txt’\n",
      "\n",
      "/tmp/vocab.txt      100%[===================>] 226.08K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2022-07-05 14:27:35 (2.93 MB/s) - ‘/tmp/vocab.txt’ saved [231508/231508]\n",
      "\n",
      "--2022-07-05 14:27:35--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156410796 (149M)\n",
      "Saving to: ‘/tmp/train.tfrecords’\n",
      "\n",
      "/tmp/train.tfrecord 100%[===================>] 149.16M  32.7MB/s    in 5.6s    \n",
      "\n",
      "2022-07-05 14:27:41 (26.5 MB/s) - ‘/tmp/train.tfrecords’ saved [156410796/156410796]\n",
      "\n",
      "--2022-07-05 14:27:41--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking//ELWC/test.tfrecords\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12432621 (12M)\n",
      "Saving to: ‘/tmp/test.tfrecords’\n",
      "\n",
      "/tmp/test.tfrecords 100%[===================>]  11.86M  21.5MB/s    in 0.6s    \n",
      "\n",
      "2022-07-05 14:27:42 (21.5 MB/s) - ‘/tmp/test.tfrecords’ saved [12432621/12432621]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"/tmp/vocab.txt\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/vocab.txt\"\n",
    "!wget -O \"/tmp/train.tfrecords\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords\"\n",
    "!wget -O \"/tmp/test.tfrecords\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking//ELWC/test.tfrecords\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7L-IOmOWm3s"
   },
   "source": [
    "Next, we discuss data formats in more detail, and show how to generate and store dummy ranking data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXA_7oIRWKd9"
   },
   "source": [
    "## Data Formats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tuna6Td3_UO"
   },
   "source": [
    "### Data Formats for Ranking\n",
    "\n",
    "For representing ranking data, [protobuffers](https://developers.google.com/protocol-buffers/) are extensible structures suitable for storing data in a serialized format, either locally or in a distributed manner.\n",
    "\n",
    "Ranking usually consists of features corresponding to each of the examples being sorted. In addition, features related to query, user or session are also useful for ranking. We refer to these as context features, as these are independent of the examples.\n",
    "\n",
    "We use the popular [tf.Example](https://www.tensorflow.org/tutorials/load_data/tfrecord) proto to represent the features for context, and each of the examples. We use the protobuffer, **ExampleListWithContext** (ELWC), to store context as a tf.Example proto and the list of examples to be ranked as a list of tf.Example protos.\n",
    "\n",
    "ExampleListWithContext protbuffer is defined [here](https://github.com/tensorflow/serving/blob/master/tensorflow_serving/apis/input.proto#L72)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95QnMu1cyPYA"
   },
   "source": [
    "Let us create some dummy data in ELWC format. We will use this dummy data to show how the proto looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "etVmJYOngOxD"
   },
   "source": [
    "Download and install the TensorFlow Ranking and TensorFlow Serving packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7xriWS-gUx3I"
   },
   "source": [
    "Let us start by importing libraries that will be used throughout this Notebook. We also enable the \"eager execution\" mode for convenience and demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "height": 198
    },
    "id": "fmlaz2D5Ux3J",
    "outputId": "df03291d-1bad-410d-e9dd-d45681e720f8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "from tensorflow_serving.apis import input_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ooOmCPHbyd02"
   },
   "outputs": [],
   "source": [
    "from google.protobuf import text_format\n",
    "\n",
    "CONTEXT = text_format.Parse(\n",
    "    \"\"\"\n",
    "    features {\n",
    "      feature {\n",
    "        key: \"query_tokens\"\n",
    "        value { bytes_list { value: [\"this\", \"is\", \"a\", \"relevant\", \"question\"] } }\n",
    "      }\n",
    "    }\"\"\", tf.train.Example())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eE7hpEBBykVS"
   },
   "outputs": [],
   "source": [
    "EXAMPLES = [\n",
    "    text_format.Parse(\n",
    "    \"\"\"\n",
    "    features {\n",
    "      feature {\n",
    "        key: \"document_tokens\"\n",
    "        value { bytes_list { value: [\"this\", \"is\", \"a\", \"relevant\", \"answer\"] } }\n",
    "      }\n",
    "      feature {\n",
    "        key: \"relevance\"\n",
    "        value { int64_list { value: 5 } }\n",
    "      }\n",
    "    }\"\"\", tf.train.Example()),\n",
    "    text_format.Parse(\n",
    "        \"\"\"\n",
    "    features {\n",
    "      feature {\n",
    "        key: \"document_tokens\"\n",
    "        value { bytes_list { value: [\"irrelevant\", \"data\"] } }\n",
    "      }\n",
    "      feature {\n",
    "        key: \"relevance\"\n",
    "        value { int64_list { value: 1 } }\n",
    "      }\n",
    "    }\"\"\", tf.train.Example()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iImhGlJyyo--"
   },
   "outputs": [],
   "source": [
    "ELWC = input_pb2.ExampleListWithContext()\n",
    "ELWC.context.CopyFrom(CONTEXT)\n",
    "for example in EXAMPLES:\n",
    "    example_features = ELWC.examples.add()\n",
    "    example_features.CopyFrom(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Wml7IFUP0XoM",
    "outputId": "a25b6962-cd6a-4fb2-9a77-13d906936668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples {\n",
      "  features {\n",
      "    feature {\n",
      "      key: \"document_tokens\"\n",
      "      value {\n",
      "        bytes_list {\n",
      "          value: \"this\"\n",
      "          value: \"is\"\n",
      "          value: \"a\"\n",
      "          value: \"relevant\"\n",
      "          value: \"answer\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    feature {\n",
      "      key: \"relevance\"\n",
      "      value {\n",
      "        int64_list {\n",
      "          value: 5\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "examples {\n",
      "  features {\n",
      "    feature {\n",
      "      key: \"document_tokens\"\n",
      "      value {\n",
      "        bytes_list {\n",
      "          value: \"irrelevant\"\n",
      "          value: \"data\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "    feature {\n",
      "      key: \"relevance\"\n",
      "      value {\n",
      "        int64_list {\n",
      "          value: 1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "context {\n",
      "  features {\n",
      "    feature {\n",
      "      key: \"query_tokens\"\n",
      "      value {\n",
      "        bytes_list {\n",
      "          value: \"this\"\n",
      "          value: \"is\"\n",
      "          value: \"a\"\n",
      "          value: \"relevant\"\n",
      "          value: \"question\"\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ELWC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_PrxvnLTO1i"
   },
   "source": [
    "### Dependencies and Global Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0B09XkzZYKLV"
   },
   "source": [
    "Here we define the train and test paths, along with model hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "SDEhIqPSYJS1"
   },
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = \"/tmp/train.tfrecords\"\n",
    "_TEST_DATA_PATH = \"/tmp/test.tfrecords\"\n",
    "\n",
    "# Store the vocabulary path for query and document tokens.\n",
    "_VOCAB_PATH = \"/tmp/vocab.txt\"\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 50\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE = \"relevance\"\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_HIDDEN_LAYER_DIMS = [\"64\", \"32\", \"16\"]\n",
    "_DROPOUT_RATE = 0.8\n",
    "_GROUP_SIZE = 1  # Pointwise scoring.\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = \"/tmp/ranking_model_dir\"\n",
    "_NUM_TRAIN_STEPS = 15 * 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFbFBTUh9WXf"
   },
   "source": [
    "## Components of a Ranking Estimator\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSIfzuaKKOa8"
   },
   "source": [
    "The overall components of a Ranking Estimator are shown below.\n",
    "\n",
    "The key components of the library are:\n",
    "\n",
    "1.   Input Reader\n",
    "2.   Tranform Function\n",
    "3.   Scoring Function\n",
    "4.   Ranking Losses\n",
    "5.   Ranking Metrics\n",
    "6.   Ranking Head\n",
    "7.   Model Builder\n",
    "\n",
    "These are described in more details in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pohq1eKbo4TD"
   },
   "source": [
    "### TensorFlow Ranking Architecture\n",
    "\n",
    "![tf_ranking_arch](https://user-images.githubusercontent.com/3262617/60061785-5f107980-96ab-11e9-9849-ace2d117220f.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aQ-VTA56sOTA"
   },
   "source": [
    "### Specifying Features via Feature Columns\n",
    "\n",
    "[Feature Columns](https://www.tensorflow.org/tutorials/structured_data/feature_columns) are TensorFlow abstractions that are used to capture rich information about each feature. It allows for easy transformations for a diverse range of raw features and for interfacing with Estimators.\n",
    "\n",
    "Consistent with our input formats for ranking, such as ELWC format, we create feature columns for context features and example features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "I0TWSuMZ70eI"
   },
   "outputs": [],
   "source": [
    "_EMBEDDING_DIMENSION = 20\n",
    "\n",
    "\n",
    "def context_feature_columns():\n",
    "    \"\"\"Returns context feature names to column definitions.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key = \"query_tokens\",\n",
    "        vocabulary_file = _VOCAB_PATH\n",
    "    )\n",
    "    query_embedding_column = tf.feature_column.embedding_column(\n",
    "        sparse_column, _EMBEDDING_DIMENSION\n",
    "    )\n",
    "    return {\"query_tokens\": query_embedding_column}\n",
    "\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "        key = \"document_tokens\",\n",
    "        vocabulary_file = _VOCAB_PATH\n",
    "    )\n",
    "    document_embedding_column = tf.feature_column.embedding_column(\n",
    "        sparse_column, _EMBEDDING_DIMENSION\n",
    "    )\n",
    "    return {\"document_tokens\": document_embedding_column}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGJ6rRJyZmiB"
   },
   "source": [
    "### Reading Input Data using *input_fn*\n",
    "\n",
    "The input reader reads in data from persistent storage to produce raw dense and sparse tensors of appropriate type for each feature. Example features are represented by 3-D tensors (where dimensions correspond to queries, examples and feature values). Context features are represented by 2-D tensors (where dimensions correspond to queries and feature values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "itrqULz5lubN"
   },
   "outputs": [],
   "source": [
    "def input_fn(path, num_epochs = None):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values()\n",
    "    )\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "        _LABEL_FEATURE, dtype = tf.int64, default_value = _PADDING_LABEL\n",
    "    )\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()) + [label_column]\n",
    "    )\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern = path,\n",
    "        data_format = tfr.data.ELWC,\n",
    "        batch_size = _BATCH_SIZE,\n",
    "        list_size = _LIST_SIZE,\n",
    "        context_feature_spec = context_feature_spec,\n",
    "        example_feature_spec = example_feature_spec,\n",
    "        reader = tf.data.TFRecordDataset,\n",
    "        shuffle = False,\n",
    "        num_epochs = num_epochs\n",
    "    )\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    label = tf.squeeze(features.pop(_LABEL_FEATURE), axis = 2)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXNUKT2s8bsQ"
   },
   "source": [
    "### Feature Transformations with *transform_fn*\n",
    "\n",
    "The transform function takes in the raw dense or sparse features from the input reader, applies suitable transformations to return dense representations for each feature. This is important before passing these features to a neural network, as neural networks layers usually take dense features as inputs.\n",
    "\n",
    "The transform function handles any custom feature transformations defined by the user. For handling sparse features, like text data, we provide an easy utlity to create shared embeddings, based on the feature columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zQG5UXub82SB"
   },
   "outputs": [],
   "source": [
    "def make_transform_fn():\n",
    "    def _transform_fn(features, mode):\n",
    "        \"\"\"Defines transform_fn.\"\"\"\n",
    "        context_features, example_features = tfr.feature.encode_listwise_features(\n",
    "            features = features,\n",
    "            context_feature_columns = context_feature_columns(),\n",
    "            example_feature_columns = example_feature_columns(),\n",
    "            mode = mode,\n",
    "            scope = \"transform_layer\"\n",
    "        )\n",
    "\n",
    "        return context_features, example_features\n",
    "\n",
    "    return _transform_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QdVFrZBIeWXL"
   },
   "source": [
    "### Feature Interactions using *scoring_fn*\n",
    "\n",
    "Next, we turn to the scoring function which is arguably at the heart of a TF Ranking model. The idea is to compute a relevance score for a (set of) query-document pair(s). The TF-Ranking model will use training data to learn this function.\n",
    "\n",
    "Here we formulate a scoring function using a feed forward network. The function takes the features of a single example (i.e., query-document pair) and produces a relevance score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B7Ft1i2oieEY"
   },
   "outputs": [],
   "source": [
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score a group of documents.\"\"\"\n",
    "        with tf.compat.v1.name_scope(\"input_layer\"):\n",
    "            context_input = [\n",
    "                tf.compat.v1.layers.flatten(context_features[name])\n",
    "                for name in sorted(context_feature_columns())\n",
    "            ]\n",
    "            group_input = [\n",
    "                tf.compat.v1.layers.flatten(group_features[name])\n",
    "                for name in sorted(example_feature_columns())\n",
    "            ]\n",
    "            input_layer = tf.concat(context_input + group_input, 1)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        cur_layer = input_layer\n",
    "        cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "            cur_layer,\n",
    "            training = is_training,\n",
    "            momentum = 0.99\n",
    "        )\n",
    "\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.compat.v1.layers.dense(cur_layer, units = layer_width)\n",
    "            cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "                cur_layer,\n",
    "                training = is_training,\n",
    "                momentum = 0.99\n",
    "            )\n",
    "            cur_layer = tf.nn.relu(cur_layer)\n",
    "            cur_layer = tf.compat.v1.layers.dropout(\n",
    "                inputs = cur_layer, rate = _DROPOUT_RATE, training = is_training\n",
    "            )\n",
    "        logits = tf.compat.v1.layers.dense(cur_layer, units = _GROUP_SIZE)\n",
    "        return logits\n",
    "\n",
    "    return _score_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQlrS6uB8_zl"
   },
   "source": [
    "## Losses, Metrics and Ranking Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0gt2bu7kbtS"
   },
   "source": [
    "### Evaluation Metrics\n",
    "\n",
    "We have provided an implementation of several popular Information Retrieval evaluation metrics in the TF Ranking library, which are shown [here](https://github.com/tensorflow/ranking/blob/d8c2e2e64a92923f1448cf5302c92a80bb469a20/tensorflow_ranking/python/metrics.py#L32). The user can also define a custom evaluation metric, as shown in the description below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YkU6o2QjkyXR"
   },
   "outputs": [],
   "source": [
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "  \n",
    "    This can be customized as follows. Care must be taken when handling padded\n",
    "    lists.\n",
    "  \n",
    "    def _auc(labels, predictions, features):\n",
    "      is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
    "      clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
    "      clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
    "      return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
    "    metric_fns[\"auc\"] = _auc\n",
    "  \n",
    "    Returns:\n",
    "      A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "    metric_fns = {}\n",
    "    metric_fns.update(\n",
    "        {\n",
    "            f\"metric/ndcg@{topn}\": tfr.metrics.make_ranking_metric_fn(\n",
    "                tfr.metrics.RankingMetricKey.NDCG, topn = topn\n",
    "            )\n",
    "            for topn in [1, 3, 5, 10]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return metric_fns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfDMGnZY9eVO"
   },
   "source": [
    "### Ranking Losses\n",
    "\n",
    "We provide several popular ranking loss functions as part of the library, which are shown [here](https://github.com/tensorflow/ranking/blob/d8c2e2e64a92923f1448cf5302c92a80bb469a20/tensorflow_ranking/python/losses.py#L35). The user can also define a custom loss function, similar to ones in tfr.losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kJSaBkxW9jZy"
   },
   "outputs": [],
   "source": [
    "# Define a loss function. To find a complete list of available\n",
    "# loss functions or to learn how to add your own custom function\n",
    "# please refer to the tensorflow_ranking.losses module.\n",
    "\n",
    "_LOSS = tfr.losses.RankingLossKey.APPROX_NDCG_LOSS\n",
    "loss_fn = tfr.losses.make_loss_fn(_LOSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUoFtZGe-pGD"
   },
   "source": [
    "### Ranking Head\n",
    "\n",
    "In the Estimator workflow, Head is an abstraction that encapsulates losses and corresponding metrics. Head easily interfaces with the Estimator, needing the user to define a scoring function and specify losses and metric computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "3pXnzLh_-rBb"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "    learning_rate = _LEARNING_RATE\n",
    ")\n",
    "\n",
    "\n",
    "def _train_op_fn(loss):\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    minimize_op = optimizer.minimize(\n",
    "        loss = loss, global_step = tf.compat.v1.train.get_global_step()\n",
    "    )\n",
    "    train_op = tf.group([update_ops, minimize_op])\n",
    "    return train_op\n",
    "\n",
    "\n",
    "ranking_head = tfr.head.create_ranking_head(\n",
    "    loss_fn = loss_fn,\n",
    "    eval_metric_fns = eval_metric_fns(),\n",
    "    train_op_fn = _train_op_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGJwvyrXk-Yj"
   },
   "source": [
    "## Putting It All Together in a Model Builder\n",
    "\n",
    "We are now ready to put all of the components above together and create an `Estimator` that can be used to train and evaluate a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XoR9hRWHlCR4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building groupwise ranking model.\n"
     ]
    }
   ],
   "source": [
    "model_fn = tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          transform_fn=make_transform_fn(),\n",
    "          group_size=_GROUP_SIZE,\n",
    "          ranking_head=ranking_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7aky8RFpH-D0"
   },
   "source": [
    "### Train and evaluate the ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7tD0aNuYU8LR"
   },
   "outputs": [],
   "source": [
    "def train_and_eval_fn():\n",
    "    \"\"\"Train and eval function used by `tf.estimator.train_and_evaluate`.\"\"\"\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        save_checkpoints_steps = 1000\n",
    "    )\n",
    "    ranker = tf.estimator.Estimator(\n",
    "        model_fn = model_fn,\n",
    "        model_dir = _MODEL_DIR,\n",
    "        config = run_config\n",
    "    )\n",
    "\n",
    "    train_input_fn = lambda: input_fn(_TRAIN_DATA_PATH)\n",
    "    eval_input_fn = lambda: input_fn(_TEST_DATA_PATH, num_epochs = 1)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn = train_input_fn, max_steps = _NUM_TRAIN_STEPS\n",
    "    )\n",
    "    eval_spec = tf.estimator.EvalSpec(\n",
    "        name = \"eval\",\n",
    "        input_fn = eval_input_fn,\n",
    "        throttle_secs = 15\n",
    "    )\n",
    "    return (ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "uXoA7xwuVmCD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/ranking_model_dir', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x7f92284ab4c0>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/layers/normalization/batch_normalization.py:532: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:26: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units = layer_width)\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:27: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:33: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:413: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:36: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units = _GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/tensorflow/python/training/adagrad.py:138: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-05 14:33:12.129262: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = -0.867506, step = 0\n",
      "INFO:tensorflow:global_step/sec: 113.494\n",
      "INFO:tensorflow:loss = -0.85956573, step = 100 (0.882 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.285\n",
      "INFO:tensorflow:loss = -0.8476943, step = 200 (0.679 sec)\n",
      "INFO:tensorflow:global_step/sec: 144.449\n",
      "INFO:tensorflow:loss = -0.80462337, step = 300 (0.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 136.999\n",
      "INFO:tensorflow:loss = -0.8051053, step = 400 (0.730 sec)\n",
      "INFO:tensorflow:global_step/sec: 138.44\n",
      "INFO:tensorflow:loss = -0.8320354, step = 500 (0.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.227\n",
      "INFO:tensorflow:loss = -0.8509389, step = 600 (0.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 130.332\n",
      "INFO:tensorflow:loss = -0.8409078, step = 700 (0.767 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.576\n",
      "INFO:tensorflow:loss = -0.8535954, step = 800 (0.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 128.842\n",
      "INFO:tensorflow:loss = -0.8268416, step = 900 (0.776 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 1000...\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 1000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:33:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.90873s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:33:22\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, labels_mean = 1.9630322, logits_mean = 1.5519431, loss = -0.7910735, metric/ndcg@1 = 0.6528571, metric/ndcg@10 = 0.82294154, metric/ndcg@3 = 0.7200978, metric/ndcg@5 = 0.76039827\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/ranking_model_dir/model.ckpt-1000\n",
      "INFO:tensorflow:global_step/sec: 32.7094\n",
      "INFO:tensorflow:loss = -0.8691673, step = 1000 (3.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 134.231\n",
      "INFO:tensorflow:loss = -0.8796949, step = 1100 (0.745 sec)\n",
      "INFO:tensorflow:global_step/sec: 131.43\n",
      "INFO:tensorflow:loss = -0.82085645, step = 1200 (0.761 sec)\n",
      "INFO:tensorflow:global_step/sec: 126.969\n",
      "INFO:tensorflow:loss = -0.8291338, step = 1300 (0.788 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.287\n",
      "INFO:tensorflow:loss = -0.8388221, step = 1400 (0.798 sec)\n",
      "INFO:tensorflow:global_step/sec: 125.53\n",
      "INFO:tensorflow:loss = -0.8516923, step = 1500 (0.797 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.808\n",
      "INFO:tensorflow:loss = -0.8553772, step = 1600 (0.821 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.069\n",
      "INFO:tensorflow:loss = -0.8111731, step = 1700 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 122.936\n",
      "INFO:tensorflow:loss = -0.8216706, step = 1800 (0.813 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.24\n",
      "INFO:tensorflow:loss = -0.85383314, step = 1900 (0.832 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 2000...\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 2000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (15 secs).\n",
      "INFO:tensorflow:global_step/sec: 103.599\n",
      "INFO:tensorflow:loss = -0.90079886, step = 2000 (0.965 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.437\n",
      "INFO:tensorflow:loss = -0.8654652, step = 2100 (0.844 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.834\n",
      "INFO:tensorflow:loss = -0.864725, step = 2200 (0.834 sec)\n",
      "INFO:tensorflow:global_step/sec: 117.666\n",
      "INFO:tensorflow:loss = -0.8557077, step = 2300 (0.850 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.309\n",
      "INFO:tensorflow:loss = -0.8849002, step = 2400 (0.845 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.91\n",
      "INFO:tensorflow:loss = -0.8293462, step = 2500 (0.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 110.493\n",
      "INFO:tensorflow:loss = -0.841729, step = 2600 (0.905 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.249\n",
      "INFO:tensorflow:loss = -0.82910526, step = 2700 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.369\n",
      "INFO:tensorflow:loss = -0.90067196, step = 2800 (0.914 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.286\n",
      "INFO:tensorflow:loss = -0.87718976, step = 2900 (0.915 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3000...\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:33:41\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.56089s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:33:41\n",
      "INFO:tensorflow:Saving dict for global step 3000: global_step = 3000, labels_mean = 1.9630322, logits_mean = 2.4233387, loss = -0.82470894, metric/ndcg@1 = 0.7228571, metric/ndcg@10 = 0.84323347, metric/ndcg@3 = 0.7519976, metric/ndcg@5 = 0.7970025\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: /tmp/ranking_model_dir/model.ckpt-3000\n",
      "INFO:tensorflow:global_step/sec: 40.1274\n",
      "INFO:tensorflow:loss = -0.8501168, step = 3000 (2.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 124.344\n",
      "INFO:tensorflow:loss = -0.8560832, step = 3100 (0.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 123.974\n",
      "INFO:tensorflow:loss = -0.8712341, step = 3200 (0.807 sec)\n",
      "INFO:tensorflow:global_step/sec: 120.481\n",
      "INFO:tensorflow:loss = -0.8576518, step = 3300 (0.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 121.096\n",
      "INFO:tensorflow:loss = -0.8522879, step = 3400 (0.826 sec)\n",
      "INFO:tensorflow:global_step/sec: 119.68\n",
      "INFO:tensorflow:loss = -0.8741164, step = 3500 (0.835 sec)\n",
      "INFO:tensorflow:global_step/sec: 118.805\n",
      "INFO:tensorflow:loss = -0.8939635, step = 3600 (0.842 sec)\n",
      "INFO:tensorflow:global_step/sec: 115.9\n",
      "INFO:tensorflow:loss = -0.8646991, step = 3700 (0.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 113.535\n",
      "INFO:tensorflow:loss = -0.8981875, step = 3800 (0.881 sec)\n",
      "INFO:tensorflow:global_step/sec: 109.539\n",
      "INFO:tensorflow:loss = -0.825547, step = 3900 (0.913 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 4000...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 4000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (15 secs).\n",
      "INFO:tensorflow:global_step/sec: 98.366\n",
      "INFO:tensorflow:loss = -0.8853167, step = 4000 (1.017 sec)\n",
      "INFO:tensorflow:global_step/sec: 103.189\n",
      "INFO:tensorflow:loss = -0.8765559, step = 4100 (0.969 sec)\n",
      "INFO:tensorflow:global_step/sec: 106.949\n",
      "INFO:tensorflow:loss = -0.8727758, step = 4200 (0.935 sec)\n",
      "INFO:tensorflow:global_step/sec: 99.1186\n",
      "INFO:tensorflow:loss = -0.89722455, step = 4300 (1.009 sec)\n",
      "INFO:tensorflow:global_step/sec: 93.8191\n",
      "INFO:tensorflow:loss = -0.86944014, step = 4400 (1.066 sec)\n",
      "INFO:tensorflow:global_step/sec: 94.7966\n",
      "INFO:tensorflow:loss = -0.8429683, step = 4500 (1.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.562\n",
      "INFO:tensorflow:loss = -0.89321613, step = 4600 (1.080 sec)\n",
      "INFO:tensorflow:global_step/sec: 88.2104\n",
      "INFO:tensorflow:loss = -0.89730173, step = 4700 (1.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 89.026\n",
      "INFO:tensorflow:loss = -0.89847326, step = 4800 (1.123 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.2579\n",
      "INFO:tensorflow:loss = -0.8859981, step = 4900 (1.187 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/tensorflow/python/training/saver.py:1052: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:34:01\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.57653s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:34:02\n",
      "INFO:tensorflow:Saving dict for global step 5000: global_step = 5000, labels_mean = 1.9630322, logits_mean = 2.3577323, loss = -0.81313914, metric/ndcg@1 = 0.73357147, metric/ndcg@10 = 0.8502235, metric/ndcg@3 = 0.7560244, metric/ndcg@5 = 0.8017828\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/ranking_model_dir/model.ckpt-5000\n",
      "INFO:tensorflow:global_step/sec: 36.4843\n",
      "INFO:tensorflow:loss = -0.8442124, step = 5000 (2.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 80.532\n",
      "INFO:tensorflow:loss = -0.8347878, step = 5100 (1.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.1707\n",
      "INFO:tensorflow:loss = -0.9010996, step = 5200 (1.263 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.7826\n",
      "INFO:tensorflow:loss = -0.88467276, step = 5300 (1.302 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.5122\n",
      "INFO:tensorflow:loss = -0.8887471, step = 5400 (1.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.1229\n",
      "INFO:tensorflow:loss = -0.8734326, step = 5500 (1.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.3311\n",
      "INFO:tensorflow:loss = -0.8362584, step = 5600 (1.186 sec)\n",
      "INFO:tensorflow:global_step/sec: 81.5745\n",
      "INFO:tensorflow:loss = -0.895329, step = 5700 (1.226 sec)\n",
      "INFO:tensorflow:global_step/sec: 82.0969\n",
      "INFO:tensorflow:loss = -0.8530057, step = 5800 (1.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.0342\n",
      "INFO:tensorflow:loss = -0.8680676, step = 5900 (1.316 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 6000...\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 6000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (15 secs).\n",
      "INFO:tensorflow:global_step/sec: 64.4846\n",
      "INFO:tensorflow:loss = -0.8636931, step = 6000 (1.550 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.4322\n",
      "INFO:tensorflow:loss = -0.86661714, step = 6100 (1.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2812\n",
      "INFO:tensorflow:loss = -0.88524675, step = 6200 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.295\n",
      "INFO:tensorflow:loss = -0.8748706, step = 6300 (1.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.1626\n",
      "INFO:tensorflow:loss = -0.86526114, step = 6400 (1.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 79.6537\n",
      "INFO:tensorflow:loss = -0.8671847, step = 6500 (1.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 85.7161\n",
      "INFO:tensorflow:loss = -0.85484767, step = 6600 (1.167 sec)\n",
      "INFO:tensorflow:global_step/sec: 92.1215\n",
      "INFO:tensorflow:loss = -0.85419625, step = 6700 (1.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.0059\n",
      "INFO:tensorflow:loss = -0.8812063, step = 6800 (1.282 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.8179\n",
      "INFO:tensorflow:loss = -0.83241034, step = 6900 (1.285 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 7000...\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 7000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:34:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.57681s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:34:30\n",
      "INFO:tensorflow:Saving dict for global step 7000: global_step = 7000, labels_mean = 1.9630322, logits_mean = 2.2888587, loss = -0.8108758, metric/ndcg@1 = 0.71357137, metric/ndcg@10 = 0.84902346, metric/ndcg@3 = 0.75467384, metric/ndcg@5 = 0.8024888\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: /tmp/ranking_model_dir/model.ckpt-7000\n",
      "INFO:tensorflow:global_step/sec: 34.3474\n",
      "INFO:tensorflow:loss = -0.8659017, step = 7000 (2.911 sec)\n",
      "INFO:tensorflow:global_step/sec: 90.0613\n",
      "INFO:tensorflow:loss = -0.87183845, step = 7100 (1.110 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.5765\n",
      "INFO:tensorflow:loss = -0.8636248, step = 7200 (1.182 sec)\n",
      "INFO:tensorflow:global_step/sec: 84.1387\n",
      "INFO:tensorflow:loss = -0.87119746, step = 7300 (1.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 83.908\n",
      "INFO:tensorflow:loss = -0.88005733, step = 7400 (1.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.6303\n",
      "INFO:tensorflow:loss = -0.8842141, step = 7500 (1.322 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 80.5571\n",
      "INFO:tensorflow:loss = -0.86421204, step = 7600 (1.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.9637\n",
      "INFO:tensorflow:loss = -0.8876715, step = 7700 (1.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.8979\n",
      "INFO:tensorflow:loss = -0.8731044, step = 7800 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.1349\n",
      "INFO:tensorflow:loss = -0.8694042, step = 7900 (1.314 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 8000...\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 8000...\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (15 secs).\n",
      "INFO:tensorflow:global_step/sec: 67.0195\n",
      "INFO:tensorflow:loss = -0.8898138, step = 8000 (1.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.9432\n",
      "INFO:tensorflow:loss = -0.85819954, step = 8100 (1.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 75.9781\n",
      "INFO:tensorflow:loss = -0.8974893, step = 8200 (1.316 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.2879\n",
      "INFO:tensorflow:loss = -0.89637315, step = 8300 (1.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.8867\n",
      "INFO:tensorflow:loss = -0.88297755, step = 8400 (1.518 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.2952\n",
      "INFO:tensorflow:loss = -0.8895935, step = 8500 (1.346 sec)\n",
      "INFO:tensorflow:global_step/sec: 74.6869\n",
      "INFO:tensorflow:loss = -0.8650003, step = 8600 (1.339 sec)\n",
      "INFO:tensorflow:global_step/sec: 78.9157\n",
      "INFO:tensorflow:loss = -0.8688534, step = 8700 (1.267 sec)\n",
      "INFO:tensorflow:global_step/sec: 76.9186\n",
      "INFO:tensorflow:loss = -0.8641963, step = 8800 (1.300 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.3929\n",
      "INFO:tensorflow:loss = -0.86319447, step = 8900 (1.603 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 9000...\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 9000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:34:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.67782s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:34:58\n",
      "INFO:tensorflow:Saving dict for global step 9000: global_step = 9000, labels_mean = 1.9630322, logits_mean = 2.115442, loss = -0.81389433, metric/ndcg@1 = 0.7321428, metric/ndcg@10 = 0.8513124, metric/ndcg@3 = 0.76328284, metric/ndcg@5 = 0.8057131\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: /tmp/ranking_model_dir/model.ckpt-9000\n",
      "INFO:tensorflow:global_step/sec: 29.3341\n",
      "INFO:tensorflow:loss = -0.91533583, step = 9000 (3.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.3465\n",
      "INFO:tensorflow:loss = -0.87589705, step = 9100 (1.604 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.9508\n",
      "INFO:tensorflow:loss = -0.897018, step = 9200 (1.614 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.4901\n",
      "INFO:tensorflow:loss = -0.8776461, step = 9300 (1.551 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.6779\n",
      "INFO:tensorflow:loss = -0.87435055, step = 9400 (1.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.5756\n",
      "INFO:tensorflow:loss = -0.9011663, step = 9500 (1.598 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.2454\n",
      "INFO:tensorflow:loss = -0.8969117, step = 9600 (1.633 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8912\n",
      "INFO:tensorflow:loss = -0.8903804, step = 9700 (1.541 sec)\n",
      "INFO:tensorflow:global_step/sec: 63.7983\n",
      "INFO:tensorflow:loss = -0.8988655, step = 9800 (1.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.5063\n",
      "INFO:tensorflow:loss = -0.89616656, step = 9900 (1.681 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:35:15\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.61793s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:35:16\n",
      "INFO:tensorflow:Saving dict for global step 10000: global_step = 10000, labels_mean = 1.9630322, logits_mean = 2.0208206, loss = -0.8189668, metric/ndcg@1 = 0.7235714, metric/ndcg@10 = 0.85050416, metric/ndcg@3 = 0.76272094, metric/ndcg@5 = 0.80554146\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/ranking_model_dir/model.ckpt-10000\n",
      "INFO:tensorflow:global_step/sec: 30.3459\n",
      "INFO:tensorflow:loss = -0.87602144, step = 10000 (3.295 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.2382\n",
      "INFO:tensorflow:loss = -0.88133, step = 10100 (1.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.2658\n",
      "INFO:tensorflow:loss = -0.9053699, step = 10200 (1.606 sec)\n",
      "INFO:tensorflow:global_step/sec: 71.5088\n",
      "INFO:tensorflow:loss = -0.8818735, step = 10300 (1.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0617\n",
      "INFO:tensorflow:loss = -0.9160841, step = 10400 (1.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 77.84\n",
      "INFO:tensorflow:loss = -0.89040416, step = 10500 (1.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.4009\n",
      "INFO:tensorflow:loss = -0.8641546, step = 10600 (1.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.7512\n",
      "INFO:tensorflow:loss = -0.87090385, step = 10700 (1.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.723\n",
      "INFO:tensorflow:loss = -0.8289364, step = 10800 (1.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.2632\n",
      "INFO:tensorflow:loss = -0.90330786, step = 10900 (1.384 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 11000...\n",
      "INFO:tensorflow:Saving checkpoints for 11000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 11000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:35:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-11000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.75038s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:35:32\n",
      "INFO:tensorflow:Saving dict for global step 11000: global_step = 11000, labels_mean = 1.9630322, logits_mean = 1.8594434, loss = -0.8241271, metric/ndcg@1 = 0.7364285, metric/ndcg@10 = 0.8542507, metric/ndcg@3 = 0.7654779, metric/ndcg@5 = 0.80941445\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 11000: /tmp/ranking_model_dir/model.ckpt-11000\n",
      "INFO:tensorflow:global_step/sec: 31.7838\n",
      "INFO:tensorflow:loss = -0.9009576, step = 11000 (3.146 sec)\n",
      "INFO:tensorflow:global_step/sec: 73.2585\n",
      "INFO:tensorflow:loss = -0.8702752, step = 11100 (1.365 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7646\n",
      "INFO:tensorflow:loss = -0.89334184, step = 11200 (1.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.8548\n",
      "INFO:tensorflow:loss = -0.9090666, step = 11300 (1.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 68.9209\n",
      "INFO:tensorflow:loss = -0.90885556, step = 11400 (1.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.0707\n",
      "INFO:tensorflow:loss = -0.89686084, step = 11500 (1.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.967\n",
      "INFO:tensorflow:loss = -0.86150444, step = 11600 (1.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 69.21\n",
      "INFO:tensorflow:loss = -0.90118587, step = 11700 (1.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.1552\n",
      "INFO:tensorflow:loss = -0.8768435, step = 11800 (1.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.8909\n",
      "INFO:tensorflow:loss = -0.8829038, step = 11900 (1.541 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 12000...\n",
      "INFO:tensorflow:Saving checkpoints for 12000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 12000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:35:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-12000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.60939s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:35:48\n",
      "INFO:tensorflow:Saving dict for global step 12000: global_step = 12000, labels_mean = 1.9630322, logits_mean = 1.7782445, loss = -0.82665503, metric/ndcg@1 = 0.725, metric/ndcg@10 = 0.8530794, metric/ndcg@3 = 0.7676841, metric/ndcg@5 = 0.80733705\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 12000: /tmp/ranking_model_dir/model.ckpt-12000\n",
      "INFO:tensorflow:global_step/sec: 30.6609\n",
      "INFO:tensorflow:loss = -0.8584012, step = 12000 (3.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.8705\n",
      "INFO:tensorflow:loss = -0.89500797, step = 12100 (1.670 sec)\n",
      "INFO:tensorflow:global_step/sec: 65.6427\n",
      "INFO:tensorflow:loss = -0.9012426, step = 12200 (1.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 72.4728\n",
      "INFO:tensorflow:loss = -0.8810508, step = 12300 (1.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4615\n",
      "INFO:tensorflow:loss = -0.89538014, step = 12400 (1.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.7915\n",
      "INFO:tensorflow:loss = -0.9008674, step = 12500 (1.543 sec)\n",
      "INFO:tensorflow:global_step/sec: 62.1465\n",
      "INFO:tensorflow:loss = -0.8763484, step = 12600 (1.609 sec)\n",
      "INFO:tensorflow:global_step/sec: 61.3809\n",
      "INFO:tensorflow:loss = -0.8964022, step = 12700 (1.629 sec)\n",
      "INFO:tensorflow:global_step/sec: 67.4697\n",
      "INFO:tensorflow:loss = -0.86294407, step = 12800 (1.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 66.6576\n",
      "INFO:tensorflow:loss = -0.8811959, step = 12900 (1.500 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 13000...\n",
      "INFO:tensorflow:Saving checkpoints for 13000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 13000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:36:05\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-13000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.60985s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:36:05\n",
      "INFO:tensorflow:Saving dict for global step 13000: global_step = 13000, labels_mean = 1.9630322, logits_mean = 1.5298153, loss = -0.82959837, metric/ndcg@1 = 0.7292857, metric/ndcg@10 = 0.8543905, metric/ndcg@3 = 0.76686454, metric/ndcg@5 = 0.8100758\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 13000: /tmp/ranking_model_dir/model.ckpt-13000\n",
      "INFO:tensorflow:global_step/sec: 30.5134\n",
      "INFO:tensorflow:loss = -0.8876227, step = 13000 (3.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 64.6678\n",
      "INFO:tensorflow:loss = -0.8851303, step = 13100 (1.546 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.8472\n",
      "INFO:tensorflow:loss = -0.88341874, step = 13200 (1.729 sec)\n",
      "INFO:tensorflow:global_step/sec: 57.4977\n",
      "INFO:tensorflow:loss = -0.8797586, step = 13300 (1.739 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.9087\n",
      "INFO:tensorflow:loss = -0.89050955, step = 13400 (1.789 sec)\n",
      "INFO:tensorflow:global_step/sec: 59.5072\n",
      "INFO:tensorflow:loss = -0.8799726, step = 13500 (1.681 sec)\n",
      "INFO:tensorflow:global_step/sec: 58.23\n",
      "INFO:tensorflow:loss = -0.9090326, step = 13600 (1.717 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.144\n",
      "INFO:tensorflow:loss = -0.8934094, step = 13700 (1.781 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.4721\n",
      "INFO:tensorflow:loss = -0.8672711, step = 13800 (1.771 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.0701\n",
      "INFO:tensorflow:loss = -0.90385586, step = 13900 (1.783 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 14000...\n",
      "INFO:tensorflow:Saving checkpoints for 14000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 14000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:36:24\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-14000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.60773s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:36:24\n",
      "INFO:tensorflow:Saving dict for global step 14000: global_step = 14000, labels_mean = 1.9630322, logits_mean = 1.3543459, loss = -0.8304062, metric/ndcg@1 = 0.74928576, metric/ndcg@10 = 0.8578283, metric/ndcg@3 = 0.7754245, metric/ndcg@5 = 0.8138965\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 14000: /tmp/ranking_model_dir/model.ckpt-14000\n",
      "INFO:tensorflow:global_step/sec: 29.3491\n",
      "INFO:tensorflow:loss = -0.8979537, step = 14000 (3.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7402\n",
      "INFO:tensorflow:loss = -0.8833914, step = 14100 (1.794 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.3698\n",
      "INFO:tensorflow:loss = -0.8927384, step = 14200 (1.806 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.5365\n",
      "INFO:tensorflow:loss = -0.8855037, step = 14300 (1.868 sec)\n",
      "INFO:tensorflow:global_step/sec: 56.8265\n",
      "INFO:tensorflow:loss = -0.8987781, step = 14400 (1.760 sec)\n",
      "INFO:tensorflow:global_step/sec: 53.6793\n",
      "INFO:tensorflow:loss = -0.8816514, step = 14500 (1.863 sec)\n",
      "INFO:tensorflow:global_step/sec: 55.7773\n",
      "INFO:tensorflow:loss = -0.91006714, step = 14600 (1.793 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.7501\n",
      "INFO:tensorflow:loss = -0.8867873, step = 14700 (2.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0368\n",
      "INFO:tensorflow:loss = -0.895471, step = 14800 (2.081 sec)\n",
      "INFO:tensorflow:global_step/sec: 54.5578\n",
      "INFO:tensorflow:loss = -0.86502105, step = 14900 (1.833 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 15000...\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/ranking_model_dir/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 15000...\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-07-05T14:36:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.61796s\n",
      "INFO:tensorflow:Finished evaluation at 2022-07-05-14:36:45\n",
      "INFO:tensorflow:Saving dict for global step 15000: global_step = 15000, labels_mean = 1.9630322, logits_mean = 1.2494025, loss = -0.8329355, metric/ndcg@1 = 0.73214287, metric/ndcg@10 = 0.8564426, metric/ndcg@3 = 0.77423865, metric/ndcg@5 = 0.811909\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/ranking_model_dir/model.ckpt-15000\n",
      "INFO:tensorflow:Loss for final step: -0.88913447.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'labels_mean': 1.9630322,\n",
       "  'logits_mean': 1.2494025,\n",
       "  'loss': -0.8329355,\n",
       "  'metric/ndcg@1': 0.73214287,\n",
       "  'metric/ndcg@10': 0.8564426,\n",
       "  'metric/ndcg@3': 0.77423865,\n",
       "  'metric/ndcg@5': 0.811909,\n",
       "  'global_step': 15000},\n",
       " [])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! rm -rf \"/tmp/ranking_model_dir\"  # Clean up the model directory.\n",
    "ranker, train_spec, eval_spec = train_and_eval_fn()\n",
    "tf.estimator.train_and_evaluate(ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45WYaJNaGfLM"
   },
   "source": [
    "### Launch TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "sHfuUVQ5D1jq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e8ef7375c448207e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e8ef7375c448207e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 12345;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=\"/tmp/ranking_model_dir\" --port 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1s1BKWSP8p_"
   },
   "source": [
    "A sample tensorboard output is shown here, with the ranking metrics.\n",
    "\n",
    "![tensorboard](https://user-images.githubusercontent.com/3262617/60866646-be0edc00-a1dd-11e9-9599-eefb734ce801.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1QymoFfDNr7"
   },
   "source": [
    "## Generating Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqHmehSKDOg1"
   },
   "source": [
    "We show how to generate predictions over the features of a dataset. We assume that the label is not present and needs to be inferred using the ranking model.\n",
    "\n",
    "Similar to the `input_fn` used for training and evaluation,  `predict_input_fn` reads in data in ELWC format and stored as TFRecords to generate features. We set number of epochs to be 1, so that the generator stops iterating when it reaches the end of the dataset. Also the datapoints are not shuffled while reading, so that the behavior of the `predict()` function is deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "vF-4BiTnDRou"
   },
   "outputs": [],
   "source": [
    "def predict_input_fn(path):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values()\n",
    "    )\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values())\n",
    "    )\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern = path,\n",
    "        data_format = tfr.data.ELWC,\n",
    "        batch_size = _BATCH_SIZE,\n",
    "        list_size = _LIST_SIZE,\n",
    "        context_feature_spec = context_feature_spec,\n",
    "        example_feature_spec = example_feature_spec,\n",
    "        reader = tf.data.TFRecordDataset,\n",
    "        shuffle = False,\n",
    "        num_epochs = 1\n",
    "    )\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVpLTPp-DVTi"
   },
   "source": [
    "We generate predictions on the test dataset, where we only consider context and example features and predict the labels. The `predict_input_fn` generates predictions on a batch of datapoints. Batching allows us to iterate over large datasets which cannot be loaded in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KVdlImkADTvK"
   },
   "outputs": [],
   "source": [
    "predictions = ranker.predict(input_fn=lambda: predict_input_fn(\"/tmp/test.tfrecords\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXh8knanDdd1"
   },
   "source": [
    "`ranker.predict` returns a generator, which we can iterate over to create predictions, till the generator is exhausted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "cROuS7-8Dd-r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in query_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:vocabulary_size = 30522 in document_tokens is inferred from the number of elements in the vocabulary_file /tmp/vocab.txt.\n",
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:8: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(context_features[name])\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:541: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:12: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
      "  tf.compat.v1.layers.flatten(group_features[name])\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:19: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/normalization.py:463: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:26: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dense(cur_layer, units = layer_width)\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:261: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:27: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "  cur_layer = tf.compat.v1.layers.batch_normalization(\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:33: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
      "  cur_layer = tf.compat.v1.layers.dropout(\n",
      "/Users/lhuang/opt/miniconda3/envs/tensorflow2.8/lib/python3.8/site-packages/keras/legacy_tf_layers/core.py:413: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
      "  return layer.apply(inputs, training=training)\n",
      "/var/folders/pl/p61pv4q90019r6vd80xnfprc0000gn/T/ipykernel_13750/3308844442.py:36: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
      "  logits = tf.compat.v1.layers.dense(cur_layer, units = _GROUP_SIZE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/ranking_model_dir/model.ckpt-15000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    }
   ],
   "source": [
    "x = next(predictions)\n",
    "assert len(x) == _LIST_SIZE  # Note that this includes padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "handling_sparse_features.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
