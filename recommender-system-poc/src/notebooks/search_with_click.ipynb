{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Input Datasets"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the date range for the last 7 days\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "date_range = 7\n",
    "end_date = datetime.now() - timedelta(days=1)\n",
    "# Add in correlationid to join search and click, tracking from 3/18/2025\n",
    "start_date = max(datetime(2025, 3, 18), end_date - timedelta(days=date_range))\n",
    "date_range = (end_date - start_date).days\n",
    "print(f\"Start date: {start_date}\")\n",
    "print(f\"End date: {end_date}\")\n",
    "print(f\"Date range: {date_range}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT _token_associate_id AS user_id,\n",
    "    click_object_id AS item_id,\n",
    "    SUM(click) AS rating\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click\n",
    "WHERE\n",
    "    click_object_id IS NOT NULL AND action = \"actions\"\n",
    "GROUP BY\n",
    "    _token_associate_id,\n",
    "    click_object_id\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df.toPandas().to_csv(\"data/input/search_click.csv\", index=False)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    click_object_id AS item_id,\n",
    "    click_details_caption AS title\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click\n",
    "WHERE\n",
    "    click_object_id IS NOT NULL AND action = \"actions\"\n",
    "GROUP BY\n",
    "    click_object_id,\n",
    "    click_details_caption\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "df.toPandas().to_csv(\"data/input/item_desc.csv\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    _token_associate_id AS user_id,\n",
    "    click_object_id AS item_id,\n",
    "    TO_UNIX_TIMESTAMP(time_stamp, 'yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'') AS unix_timestamp,\n",
    "    SUM(click) AS rating\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click\n",
    "WHERE\n",
    "    click_object_id IS NOT NULL AND action = \"actions\"\n",
    "GROUP BY\n",
    "    _token_associate_id,\n",
    "    click_object_id,\n",
    "    TO_UNIX_TIMESTAMP(time_stamp, 'yyyy-MM-dd\\'T\\'HH:mm:ss.SSS\\'Z\\'')\n",
    "\"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.toPandas().to_csv(\"data/input/search_click_ts\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    click_object_id AS item_id,\n",
    "    click_details_caption AS title,\n",
    "    concat_ws('|', collect_set(client_id)) AS categories\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click\n",
    "WHERE\n",
    "    click_object_id IS NOT NULL and action = \"actions\"\n",
    "GROUP BY\n",
    "    click_object_id,\n",
    "    click_details_caption\n",
    " \"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.toPandas().to_csv(\"data/input/item_desc_clientid\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    view._token_associate_id AS user_id,\n",
    "    view._id AS item_id,\n",
    "    view.click AS rating\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click AS view\n",
    "JOIN\n",
    "    (\n",
    "        SELECT\n",
    "            traceId,\n",
    "            MAX(resPos) AS max_resPos\n",
    "        FROM\n",
    "            onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click\n",
    "        WHERE\n",
    "            click_object_id IS NOT NULL\n",
    "        GROUP BY\n",
    "            traceId\n",
    "    ) AS click\n",
    "ON\n",
    "    view.traceId = click.traceId\n",
    "    AND view.resPos <= click.max_resPos\n",
    "WHERE view.action = \"actions\"\n",
    " \"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.toPandas().to_csv(\"data/input/view_click.csv\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT DISTINCT\n",
    "    _token_associate_id AS user_id,\n",
    "    LAST_VALUE(user_agent) OVER (\n",
    "        PARTITION BY _token_associate_id\n",
    "        ORDER BY time_stamp\n",
    "        ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING\n",
    "    ) AS last_user_agent\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.ml_search_with_click\n",
    " \"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.toPandas().to_csv(\"data/input/user_desc.csv\", index=False)"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load Output Datasets"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "    *\n",
    "FROM\n",
    "    onedata_us_east_1_shared_dit.nas_raw_lyric_search_dit.cold_start_recommended_actions\n",
    " \"\"\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "df.toPandas().to_csv(\"data/output/cold_start.csv\", index=False)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
