{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b266fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random, math, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8c2781c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.70710678],\n",
       "       [0.70710678, 1.        ]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "i = [1, 0, 0, 0]\n",
    "j = [1, 0, 1, 0]\n",
    "cosine_similarity([i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05ba223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.816496580927726, pvalue=0.18350341907227397)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "i = [1, 0, 0, 0]\n",
    "j = [1, 0.5, 0.5, 0]\n",
    "pearsonr(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3399feab",
   "metadata": {},
   "source": [
    "### UserCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87788a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    users = {'Alice': {'A': 5, 'B': 3, 'C': 4, 'D': 4},\n",
    "             'user1': {'A': 3, 'B': 1, 'C': 2, 'D': 3, 'E': 3},\n",
    "             'user2': {'A': 4, 'B': 3, 'C': 4, 'D': 3, 'E': 5},\n",
    "             'user3': {'A': 3, 'B': 3, 'C': 1, 'D': 5, 'E': 4},\n",
    "             'user4': {'A': 1, 'B': 5, 'C': 5, 'D': 2, 'E': 1}\n",
    "             }\n",
    "    return users\n",
    "\n",
    "user_data = loadData()\n",
    "\n",
    "similarity_matrix = pd.DataFrame(\n",
    "    np.identity(len(user_data)),\n",
    "    index=user_data.keys(),\n",
    "    columns=user_data.keys(),\n",
    ")\n",
    "\n",
    "# 遍历每条用户-物品评分数据\n",
    "for u1, items1 in user_data.items():\n",
    "    for u2, items2 in user_data.items():\n",
    "        if u1 == u2:\n",
    "            continue\n",
    "        vec1, vec2 = [], []\n",
    "        for item, rating1 in items1.items():\n",
    "            rating2 = items2.get(item, -1)\n",
    "            if rating2 == -1:\n",
    "                continue\n",
    "            vec1.append(rating1)\n",
    "            vec2.append(rating2)\n",
    "        # 计算不同用户之间的皮尔逊相关系数\n",
    "        similarity_matrix[u1][u2] = np.corrcoef(vec1, vec2)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8c9dc19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alice</th>\n",
       "      <th>user1</th>\n",
       "      <th>user2</th>\n",
       "      <th>user3</th>\n",
       "      <th>user4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852803</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.792118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>0.852803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.467707</td>\n",
       "      <td>0.489956</td>\n",
       "      <td>-0.900149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.467707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.161165</td>\n",
       "      <td>-0.466569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.489956</td>\n",
       "      <td>-0.161165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.641503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>-0.792118</td>\n",
       "      <td>-0.900149</td>\n",
       "      <td>-0.466569</td>\n",
       "      <td>-0.641503</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Alice     user1     user2     user3     user4\n",
       "Alice  1.000000  0.852803  0.707107  0.000000 -0.792118\n",
       "user1  0.852803  1.000000  0.467707  0.489956 -0.900149\n",
       "user2  0.707107  0.467707  1.000000 -0.161165 -0.466569\n",
       "user3  0.000000  0.489956 -0.161165  1.000000 -0.641503\n",
       "user4 -0.792118 -0.900149 -0.466569 -0.641503  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff4e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与用户Alice最相似的2个用户为：['user1', 'user2']\n"
     ]
    }
   ],
   "source": [
    "target_user = 'Alice'\n",
    "num = 2\n",
    "# 由于最相似的用户为自己，去除本身\n",
    "sim_users = similarity_matrix[target_user].sort_values(ascending=False)[1:num+1].index.tolist()\n",
    "print(f'与用户{target_user}最相似的{num}个用户为：{sim_users}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e8b145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户Alice对物品E的预测评分为：4.871979899370592\n"
     ]
    }
   ],
   "source": [
    "weighted_scores = 0.\n",
    "corr_values_sum = 0.\n",
    "\n",
    "target_item = 'E'\n",
    "# 基于皮尔逊相关系数预测用户评分\n",
    "for user in sim_users:\n",
    "    corr_value = similarity_matrix[target_user][user]\n",
    "    user_mean_rating = np.mean(list(user_data[user].values()))\n",
    "\n",
    "    weighted_scores += corr_value * (user_data[user][target_item] - user_mean_rating)\n",
    "    corr_values_sum += corr_value\n",
    "\n",
    "target_user_mean_rating = np.mean(list(user_data[target_user].values()))\n",
    "target_item_pred = target_user_mean_rating + weighted_scores / corr_values_sum\n",
    "print(f'用户{target_user}对物品{target_item}的预测评分为：{target_item_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d13f1f",
   "metadata": {},
   "source": [
    "### ItemCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4abc2403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Alice</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A    B    C    D    E\n",
       "Alice  5.0  3.0  4.0  4.0  NaN\n",
       "user1  3.0  1.0  2.0  3.0  3.0\n",
       "user2  4.0  3.0  4.0  3.0  5.0\n",
       "user3  3.0  3.0  1.0  5.0  4.0\n",
       "user4  1.0  5.0  5.0  2.0  1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def loadData():\n",
    "    items = {'A': {'Alice': 5.0, 'user1': 3.0, 'user2': 4.0, 'user3': 3.0, 'user4': 1.0},\n",
    "             'B': {'Alice': 3.0, 'user1': 1.0, 'user2': 3.0, 'user3': 3.0, 'user4': 5.0},\n",
    "             'C': {'Alice': 4.0, 'user1': 2.0, 'user2': 4.0, 'user3': 1.0, 'user4': 5.0},\n",
    "             'D': {'Alice': 4.0, 'user1': 3.0, 'user2': 3.0, 'user3': 5.0, 'user4': 2.0},\n",
    "             'E': {'user1': 3.0, 'user2': 5.0, 'user3': 4.0, 'user4': 1.0}\n",
    "             }\n",
    "    return items\n",
    "\n",
    "item_data = loadData()\n",
    "pd.DataFrame(item_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76001dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D    E\n",
       "A  1.0  0.0  0.0  0.0  0.0\n",
       "B  0.0  1.0  0.0  0.0  0.0\n",
       "C  0.0  0.0  1.0  0.0  0.0\n",
       "D  0.0  0.0  0.0  1.0  0.0\n",
       "E  0.0  0.0  0.0  0.0  1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = pd.DataFrame(\n",
    "    np.identity(len(item_data)),\n",
    "    index=item_data.keys(),\n",
    "    columns=item_data.keys(),\n",
    ")\n",
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89cfa250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 遍历每条物品-用户评分数据\n",
    "for i1, users1 in item_data.items():\n",
    "    for i2, users2 in item_data.items():\n",
    "        if i1 == i2:\n",
    "            continue\n",
    "        vec1, vec2 = [], []\n",
    "        for user, rating1 in users1.items():\n",
    "            rating2 = users2.get(user, -1)\n",
    "            if rating2 == -1:\n",
    "                continue\n",
    "            vec1.append(rating1)\n",
    "            vec2.append(rating2)\n",
    "        similarity_matrix[i1][i2] = np.corrcoef(vec1, vec2)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a0a4b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.476731</td>\n",
       "      <td>-0.123091</td>\n",
       "      <td>0.532181</td>\n",
       "      <td>0.969458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>-0.476731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>-0.310087</td>\n",
       "      <td>-0.478091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>-0.123091</td>\n",
       "      <td>0.645497</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.720577</td>\n",
       "      <td>-0.427618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>0.532181</td>\n",
       "      <td>-0.310087</td>\n",
       "      <td>-0.720577</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.581675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>0.969458</td>\n",
       "      <td>-0.478091</td>\n",
       "      <td>-0.427618</td>\n",
       "      <td>0.581675</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          A         B         C         D         E\n",
       "A  1.000000 -0.476731 -0.123091  0.532181  0.969458\n",
       "B -0.476731  1.000000  0.645497 -0.310087 -0.478091\n",
       "C -0.123091  0.645497  1.000000 -0.720577 -0.427618\n",
       "D  0.532181 -0.310087 -0.720577  1.000000  0.581675\n",
       "E  0.969458 -0.478091 -0.427618  0.581675  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ce7ea4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "与物品E最相似的2个物品为：['A', 'D']\n"
     ]
    }
   ],
   "source": [
    "target_user = 'Alice'\n",
    "target_item = 'E'\n",
    "num = 2\n",
    "\n",
    "sim_items = []\n",
    "sim_items_list = similarity_matrix[target_item].sort_values(ascending=False).index.tolist()\n",
    "for item in sim_items_list:\n",
    "    # 如果target_user对物品item评分过\n",
    "    if target_user in item_data[item]:\n",
    "        sim_items.append(item)\n",
    "    if len(sim_items) == num:\n",
    "        break\n",
    "print(f'与物品{target_item}最相似的{num}个物品为：{sim_items}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "751ef999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "用户Alice对物品E的预测评分为：4.6\n"
     ]
    }
   ],
   "source": [
    "target_user_mean_rating = np.mean(list(item_data[target_item].values()))\n",
    "weighted_scores = 0.\n",
    "corr_values_sum = 0.\n",
    "\n",
    "target_item = 'E'\n",
    "for item in sim_items:\n",
    "    corr_value = similarity_matrix[target_item][item]\n",
    "    user_mean_rating = np.mean(list(item_data[item].values()))\n",
    "\n",
    "    weighted_scores += corr_value * (item_data[item][target_user] - user_mean_rating)\n",
    "    corr_values_sum += corr_value\n",
    "\n",
    "target_item_pred = target_user_mean_rating + weighted_scores / corr_values_sum\n",
    "print(f'用户{target_user}对物品{target_item}的预测评分为：{target_item_pred}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c794f3a",
   "metadata": {},
   "source": [
    "### Swing(Graph-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba71e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "14c89926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    items = {'A': {'Alice': 5.0, 'user1': 3.0, 'user2': 4.0, 'user3': 3.0, 'user4': 1.0},\n",
    "             'B': {'Alice': 3.0, 'user1': 1.0, 'user2': 3.0, 'user3': 3.0, 'user4': 5.0},\n",
    "             'C': {'Alice': 4.0, 'user1': 2.0, 'user2': 4.0, 'user3': 1.0, 'user4': 5.0},\n",
    "             'D': {'Alice': 4.0, 'user1': 3.0, 'user2': 3.0, 'user3': 5.0, 'user4': 2.0},\n",
    "             'E': {'user1': 3.0, 'user2': 5.0, 'user3': 4.0, 'user4': 1.0}\n",
    "             }\n",
    "    return items\n",
    "\n",
    "df = pd.DataFrame(loadData()).transpose()\n",
    "df = df.reset_index().melt(id_vars='index', value_name='rate').dropna()\n",
    "df.columns = ['itemid', 'userid', 'rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92edde9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>userid</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>Alice</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Alice</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>Alice</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>D</td>\n",
       "      <td>Alice</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A</td>\n",
       "      <td>user1</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  itemid userid  rate\n",
       "0      A  Alice   5.0\n",
       "1      B  Alice   3.0\n",
       "2      C  Alice   4.0\n",
       "3      D  Alice   4.0\n",
       "5      A  user1   3.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50f5de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uitems_iusers(train):\n",
    "    u_items = dict()\n",
    "    i_users = dict()\n",
    "    for index, row in train.iterrows():#处理用户交互记录 \n",
    "        u_items.setdefault(row[\"userid\"], set())\n",
    "        i_users.setdefault(row[\"itemid\"], set())\n",
    "        u_items[row[\"userid\"]].add(row[\"itemid\"])#得到user交互过的所有item\n",
    "        i_users[row[\"itemid\"]].add(row[\"userid\"])#得到item交互过的所有user\n",
    "    print(\"使用的用户个数为：{}\".format(len(u_items)))\n",
    "    print(\"使用的item个数为：{}\".format(len(i_users)))\n",
    "    return u_items, i_users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4007b2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用的用户个数为：5\n",
      "使用的item个数为：5\n"
     ]
    }
   ],
   "source": [
    "u_items, i_users = get_uitems_iusers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7c403f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "def swing_model(u_items, i_users):\n",
    "#     print([i for i in i_users.values()][:5])\n",
    "#     print([i for i in u_items.values()][:5])\n",
    "    item_pairs = list(combinations(i_users.keys(), 2)) #全排列组合对\n",
    "    print(\"item pairs length：{}\".format(len(item_pairs)))\n",
    "    item_sim_dict = dict()\n",
    "    for (i, j) in item_pairs:\n",
    "        user_pairs = list(combinations(i_users[i] & i_users[j], 2)) #item_i和item_j对应的user取交集后全排列 得到user对\n",
    "        result = 0\n",
    "        for (u, v) in user_pairs:\n",
    "            result += 1 / (alpha + list(u_items[u] & u_items[v]).__len__()) #分数公式\n",
    "        if result != 0 :\n",
    "            item_sim_dict.setdefault(i, dict())\n",
    "            item_sim_dict[i][j] = format(result, '.6f')\n",
    "    return item_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "65dba39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item pairs length：10\n"
     ]
    }
   ],
   "source": [
    "item_sim_dict = swing_model(u_items, i_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8419de55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': {'B': '1.979798', 'C': '1.979798', 'D': '1.979798', 'E': '1.090909'},\n",
       " 'B': {'C': '1.979798', 'D': '1.979798', 'E': '1.090909'},\n",
       " 'C': {'D': '1.979798', 'E': '1.090909'},\n",
       " 'D': {'E': '1.090909'}}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_sim_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c2628c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item_id: A\t{'B': '1.979798', 'C': '1.979798'}\n",
      "item_id: B\t{'C': '1.979798', 'D': '1.979798'}\n",
      "item_id: C\t{'D': '1.979798', 'E': '1.090909'}\n",
      "item_id: D\t{'E': '1.090909'}\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "top_k = 2\n",
    "new_item_sim_dict = dict()\n",
    "for item, sim_items in item_sim_dict.items():\n",
    "    new_item_sim_dict.setdefault(item, dict())\n",
    "    new_item_sim_dict[item] = dict(sorted(sim_items.items(), key = lambda k:k[1], reverse=True)[:top_k])#排序取出 top_k个相似的item\n",
    "    print(f'item_id: {item}\\t{new_item_sim_dict[item]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d38b99",
   "metadata": {},
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d3c6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0a1e98",
   "metadata": {},
   "source": [
    "在推荐系统中，评分预测除了与用户的兴趣偏好、物品的特征属性相关外，与其他的因素也相关。例如：\n",
    "\n",
    "例如，对于乐观的用户来说，它的评分行为普遍偏高，而对批判性用户来说，他的评分记录普遍偏低，即使他们对同一物品的评分相同，但是他们对该物品的喜好程度却并不一样。\n",
    "对物品来说也是类似的。以电影为例，受大众欢迎的电影得到的评分普遍偏高，而一些烂片的评分普遍偏低，这些因素都是独立于用户或产品的因素，和用户对产品的的喜好无关。\n",
    "因此在原来的基础上加了偏置项， 来消除用户和物品打分的偏差， 即预测公式如下：\n",
    "\n",
    "- μ： 该参数反映的是推荐模型整体的平均评分，一般使用所有样本评分的均值。\n",
    "- b_u：用户偏差系数。可以使用用户 u 给出的所有评分的均值， 也可以当做训练参数。\n",
    "这一项表示了用户的评分习惯中和物品没有关系的那种因素。 比如有些用户比较苛刻， 对什么东西要求很高， 那么他评分就会偏低， 而有些用户比较宽容， 对什么东西都觉得不错， 那么评分就偏高\n",
    "- b_i ：物品偏差系数。可以使用物品 i 收到的所有评分的均值， 也可以当做训练参数。\n",
    "这一项表示了物品接受的评分中和用户没有关系的因素。 比如有些物品本身质量就很高， 因此获得的评分相对比较高， 有的物品本身质量很差， 因此获得的评分相对较低。\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min _{q^*, p^*} \\frac{1}{2} \\sum_{(u, i) \\in K} & \\left(r_{u i}-\\left(\\mu+b_u+b_i+q_i^T p_u\\right)\\right)^2 \\\\\n",
    "& +\\lambda\\left(\\left\\|p_u\\right\\|^2+\\left\\|q_i\\right\\|^2+b_u^2+b_i^2\\right)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial b_{u}} S S E=-e_{u i}+\\lambda b_{u} \\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c55b16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiasSVD():\n",
    "    def __init__(self, rating_data, F=5, alpha=0.1, lmbda=0.1, max_iter=100):\n",
    "        self.F = F          # 这个表示隐向量的维度\n",
    "        self.P = dict()     # 用户矩阵P  大小是[users_num, F]\n",
    "        self.Q = dict()     # 物品矩阵Q  大小是[item_nums, F]\n",
    "        self.bu = dict()    # 用户偏置系数\n",
    "        self.bi = dict()    # 物品偏置系数\n",
    "        self.mu = 0         # 全局偏置系数\n",
    "        self.alpha = alpha  # 学习率\n",
    "        self.lmbda = lmbda  # 正则项系数\n",
    "        self.max_iter = max_iter        # 最大迭代次数\n",
    "        self.rating_data = rating_data  # 评分矩阵\n",
    "\n",
    "        for user, items in self.rating_data.items():\n",
    "            # 初始化矩阵P和Q, 随机数需要和1/sqrt(F)成正比\n",
    "            self.P[user] = [random.random() / math.sqrt(self.F) for x in range(0, F)]\n",
    "            self.bu[user] = 0\n",
    "            for item, rating in items.items():\n",
    "                if item not in self.Q:\n",
    "                    self.Q[item] = [random.random() / math.sqrt(self.F) for x in range(0, F)]\n",
    "                    self.bi[item] = 0\n",
    "\n",
    "    # 采用随机梯度下降的方式训练模型参数\n",
    "    def train(self):\n",
    "        cnt, mu_sum = 0, 0\n",
    "        for user, items in self.rating_data.items():\n",
    "            for item, rui in items.items():\n",
    "                mu_sum, cnt = mu_sum + rui, cnt + 1\n",
    "        self.mu = mu_sum / cnt\n",
    "\n",
    "        for step in range(self.max_iter):\n",
    "            # 遍历所有的用户及历史交互物品\n",
    "            for user, items in self.rating_data.items():\n",
    "                # 遍历历史交互物品\n",
    "                for item, rui in items.items():\n",
    "                    rhat_ui = self.predict(user, item)  # 评分预测\n",
    "                    e_ui = rui - rhat_ui                  # 评分预测偏差\n",
    "\n",
    "                    # 参数更新\n",
    "                    self.bu[user] += self.alpha * (e_ui - self.lmbda * self.bu[user])\n",
    "                    self.bi[item] += self.alpha * (e_ui - self.lmbda * self.bi[item])\n",
    "                    for k in range(0, self.F):\n",
    "                        self.P[user][k] += self.alpha * (e_ui * self.Q[item][k] - self.lmbda * self.P[user][k])\n",
    "                        self.Q[item][k] += self.alpha * (e_ui * self.P[user][k] - self.lmbda * self.Q[item][k])\n",
    "            # 逐步降低学习率\n",
    "            self.alpha *= 0.1\n",
    "\n",
    "\n",
    "    # 评分预测\n",
    "    def predict(self, user, item):\n",
    "        return sum(self.P[user][f] * self.Q[item][f] for f in range(0, self.F)) + self.bu[user] + self.bi[item] + self.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e99041c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过字典初始化训练样本，分别表示不同用户（1-5）对不同物品（A-E)的真实评分\n",
    "def loadData():\n",
    "    rating_data={1: {'A': 5, 'B': 3, 'C': 4, 'D': 4},\n",
    "           2: {'A': 3, 'B': 1, 'C': 2, 'D': 3, 'E': 3},\n",
    "           3: {'A': 4, 'B': 3, 'C': 4, 'D': 3, 'E': 5},\n",
    "           4: {'A': 3, 'B': 3, 'C': 1, 'D': 5, 'E': 4},\n",
    "           5: {'A': 1, 'B': 5, 'C': 5, 'D': 2, 'E': 1}\n",
    "          }\n",
    "    return rating_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d38d195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "rating_data = loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f638c938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "basicsvd = BiasSVD(rating_data, F=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d011da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数训练\n",
    "basicsvd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842fdc5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E 3.702643720184852\n"
     ]
    }
   ],
   "source": [
    "# 预测用户1对物品E的评分\n",
    "for item in ['E']:\n",
    "    print(item, basicsvd.predict(1, item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e054f08b",
   "metadata": {},
   "source": [
    "### User_CF with Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33f1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 评价指标\n",
    "# 推荐系统推荐正确的商品数量占用户实际点击的商品数量\n",
    "def Recall(Rec_dict, Val_dict):\n",
    "    '''\n",
    "    Rec_dict: 推荐算法返回的推荐列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...} \n",
    "    Val_dict: 用户实际点击的商品列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...}\n",
    "    '''\n",
    "    hit_items = 0\n",
    "    all_items = 0\n",
    "    for uid, items in Val_dict.items():\n",
    "        rel_set = items\n",
    "        rec_set = Rec_dict[uid]\n",
    "        for item in rec_set:\n",
    "            if item in rel_set:\n",
    "                hit_items += 1\n",
    "        all_items += len(rel_set)\n",
    "\n",
    "    return round(hit_items / all_items * 100, 2)\n",
    "\n",
    "# 推荐系统推荐正确的商品数量占给用户实际推荐的商品数\n",
    "def Precision(Rec_dict, Val_dict):\n",
    "    '''\n",
    "    Rec_dict: 推荐算法返回的推荐列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...} \n",
    "    Val_dict: 用户实际点击的商品列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...}\n",
    "    '''\n",
    "    hit_items = 0\n",
    "    all_items = 0\n",
    "    for uid, items in Val_dict.items():\n",
    "        rel_set = items\n",
    "        rec_set = Rec_dict[uid]\n",
    "        for item in rec_set:\n",
    "            if item in rel_set:\n",
    "                hit_items += 1\n",
    "        all_items += len(rec_set)\n",
    "\n",
    "    return round(hit_items / all_items * 100, 2)\n",
    "\n",
    "# 所有被推荐的用户中,推荐的商品数量占这些用户实际被点击的商品数量\n",
    "def Coverage(Rec_dict, Trn_dict):\n",
    "    '''\n",
    "    Rec_dict: 推荐算法返回的推荐列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...} \n",
    "    Trn_dict: 训练集用户实际点击的商品列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...}\n",
    "    '''\n",
    "    rec_items = set()\n",
    "    all_items = set()\n",
    "    for uid in Rec_dict:\n",
    "        for item in Trn_dict[uid]:\n",
    "            all_items.add(item)\n",
    "        for item in Rec_dict[uid]:\n",
    "            rec_items.add(item)\n",
    "    return round(len(rec_items) / len(all_items) * 100, 2)\n",
    "\n",
    "# 使用平均流行度度量新颖度,如果平均流行度很高(即推荐的商品比较热门),说明推荐的新颖度比较低\n",
    "def Popularity(Rec_dict, Trn_dict):\n",
    "    '''\n",
    "    Rec_dict: 推荐算法返回的推荐列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...} \n",
    "    Trn_dict: 训练集用户实际点击的商品列表, 形式:{uid: {item1, item2,...}, uid: {item1, item2,...}, ...}\n",
    "    '''\n",
    "    pop_items = {}\n",
    "    for uid in Trn_dict:\n",
    "        for item in Trn_dict[uid]:\n",
    "            if item not in pop_items:\n",
    "                pop_items[item] = 0\n",
    "            pop_items[item] += 1\n",
    "    \n",
    "    pop, num = 0, 0\n",
    "    for uid in Rec_dict:\n",
    "        for item in Rec_dict[uid]:\n",
    "            pop += math.log(pop_items[item] + 1) # 物品流行度分布满足长尾分布,取对数可以使得平均值更稳定\n",
    "            num += 1  \n",
    "    return round(pop / num, 3)\n",
    "\n",
    "# 将几个评价指标指标函数一起调用\n",
    "def rec_eval(val_rec_items, val_user_items, trn_user_items):\n",
    "    print('recall:',Recall(val_rec_items, val_user_items))\n",
    "    print('precision',Precision(val_rec_items, val_user_items))\n",
    "    print('coverage',Coverage(val_rec_items, trn_user_items))\n",
    "    print('Popularity',Popularity(val_rec_items, trn_user_items))\n",
    "\n",
    "def get_data(root_path):\n",
    "    # 读取数据\n",
    "    rnames = ['user_id','movie_id','rating','timestamp']\n",
    "    ratings = pd.read_csv(os.path.join(root_path, 'ratings.dat'), sep='::', engine='python', names=rnames)\n",
    "    \n",
    "    # 分割训练和验证集\n",
    "    trn_data, val_data, _, _ = train_test_split(ratings, ratings, test_size=0.2)\n",
    "    \n",
    "    trn_data = trn_data.groupby('user_id')['movie_id'].apply(list).reset_index()\n",
    "    val_data = val_data.groupby('user_id')['movie_id'].apply(list).reset_index()\n",
    "\n",
    "    trn_user_items = {}\n",
    "    val_user_items = {}\n",
    "    \n",
    "    # 将数组构造成字典的形式{user_id: [item_id1, item_id2,...,item_idn]}\n",
    "    for user, movies in zip(*(list(trn_data['user_id']), list(trn_data['movie_id']))):\n",
    "        trn_user_items[user] = set(movies)\n",
    "\n",
    "    for user, movies in zip(*(list(val_data['user_id']), list(val_data['movie_id']))):\n",
    "        val_user_items[user] = set(movies)\n",
    "    \n",
    "    return trn_user_items, val_user_items\n",
    "\n",
    "def User_CF_Rec(trn_user_items, val_user_items, K, N):\n",
    "    '''\n",
    "    trn_user_items: 表示训练数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    val_user_items: 表示验证数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    K: Ｋ表示的是相似用户的数量，每个用户都选择与其最相似的K个用户\n",
    "    N: N表示的是给用户推荐的商品数量，给每个用户推荐相似度最大的N个商品\n",
    "    '''\n",
    "\n",
    "    # 建立item->users倒排表\n",
    "    # 倒排表的格式为: {item_id1: {user_id1, user_id2, ... , user_idn}, item_id2: ...} 也就是每个item对应有那些用户有过点击\n",
    "    # 建立倒排表的目的就是为了更好的统计用户之间共同交互的商品数量\n",
    "    print('建立倒排表...')\n",
    "    item_users = {}\n",
    "    for uid, items in tqdm(trn_user_items.items()): # 遍历每一个用户的数据,其中包含了该用户所有交互的item\n",
    "        for item in items: # 遍历该用户的所有item, 给这些item对应的用户列表添加对应的uid\n",
    "            if item not in item_users:\n",
    "                item_users[item] = set()\n",
    "            item_users[item].add(uid)\n",
    "    \n",
    "\n",
    "    # 计算用户协同过滤矩阵\n",
    "    # 即利用item-users倒排表统计用户之间交互的商品数量，用户协同过滤矩阵的表示形式为：sim = {user_id1: {user_id2: num1}, user_id3:{user_id4: num2}, ...}\n",
    "    # 协同过滤矩阵是一个双层的字典，用来表示用户之间共同交互的商品数量\n",
    "    # 在计算用户协同过滤矩阵的同时还需要记录每个用户所交互的商品数量，其表示形式为: num = {user_id1：num1, user_id2:num2, ...}\n",
    "    sim = {}\n",
    "    num = {}\n",
    "    print('构建协同过滤矩阵...')\n",
    "    for item, users in tqdm(item_users.items()): # 遍历所有的item去统计,用户两辆之间共同交互的item数量\n",
    "        for u in users:\n",
    "            if u not in num: # 如果用户u不在字典num中，提前给其在字典中初始化为0,否则后面的运算会报key error\n",
    "                num[u] = 0\n",
    "            num[u] += 1 # 统计每一个用户,交互的总的item的数量\n",
    "            if u not in sim: # 如果用户u不在字典sim中，提前给其在字典中初始化为一个新的字典,否则后面的运算会报key error\n",
    "                sim[u] = {}\n",
    "            for v in users:\n",
    "                if u != v:  # 只有当u不等于v的时候才计算用户之间的相似度　\n",
    "                    if v not in sim[u]:\n",
    "                        sim[u][v] = 0\n",
    "                    sim[u][v] += 1\n",
    "                    \n",
    "\n",
    "    # 计算用户相似度矩阵\n",
    "    # 用户协同过滤矩阵其实相当于是余弦相似度的分子部分,还需要除以分母,即两个用户分别交互的item数量的乘积\n",
    "    # 两个用户分别交互的item数量的乘积就是上面统计的num字典\n",
    "    print('计算相似度...')\n",
    "    for u, users in tqdm(sim.items()):\n",
    "        for v, score in users.items():\n",
    "            sim[u][v] =  score / math.sqrt(num[u] * num[v]) # 余弦相似度分母部分 \n",
    "    \n",
    "\n",
    "    # 对验证数据中的每个用户进行TopN推荐\n",
    "    # 在对用户进行推荐之前需要先通过相似度矩阵得到与当前用户最相思的前K个用户，\n",
    "    # 然后对这K个用户交互的商品中除当前测试用户训练集中交互过的商品以外的商品计算最终的相似度分数\n",
    "    # 最终推荐的候选商品的相似度分数是由多个用户对该商品分数的一个累加和\n",
    "    print('给测试用户进行推荐...')\n",
    "    items_rank = {}\n",
    "    for u, _ in tqdm(val_user_items.items()): # 遍历测试集用户，给测试集中的每个用户进行推荐\n",
    "        items_rank[u] = {} # 初始化用户u的候选item的字典\n",
    "        for v, score in sorted(sim[u].items(), key=lambda x: x[1], reverse=True)[:K]: # 选择与用户u最相思的k个用户\n",
    "            for item in trn_user_items[v]: # 遍历相似用户之间交互过的商品\n",
    "                if item not in trn_user_items[u]: # 如果相似用户交互过的商品，测试用户在训练集中出现过，就不用进行推荐，直接跳过\n",
    "                    if item not in items_rank[u]:\n",
    "                        items_rank[u][item] = 0   # 初始化用户u对item的相似度分数为０\n",
    "                    items_rank[u][item] += score  # 累加所有相似用户对同一个item的分数\n",
    "    \n",
    "    print('为每个用户筛选出相似度分数最高的Ｎ个商品...')\n",
    "    items_rank = {k: sorted(v.items(), key=lambda x: x[1], reverse=True)[:N] for k, v in items_rank.items()}\n",
    "    items_rank = {k: set([x[0] for x in v]) for k, v in items_rank.items()} # 将输出整合成合适的格式输出\n",
    "        \n",
    "    return items_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dd9ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../data/ml-1m/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec49d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_user_items, val_user_items = get_data(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "501241a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "建立倒排表...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6040/6040 [00:00<00:00, 26271.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建协同过滤矩阵...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3681/3681 [01:28<00:00, 41.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算相似度...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6040/6040 [00:08<00:00, 706.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给测试用户进行推荐...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6033/6033 [00:33<00:00, 177.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n",
      "recall: 10.22\n",
      "precision 33.88\n",
      "coverage 19.83\n",
      "Popularity 7.228\n"
     ]
    }
   ],
   "source": [
    "rec_items = User_CF_Rec(trn_user_items, val_user_items, 80, 10)\n",
    "rec_eval(rec_items, val_user_items, trn_user_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b65e2",
   "metadata": {},
   "source": [
    "### ItemCF with Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bea81a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Item_CF(trn_user_items, val_user_items, K, N):\n",
    "    '''\n",
    "    trn_user_items: 表示训练数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    val_user_items: 表示验证数据，格式为：{user_id1: [item_id1, item_id2,...,item_idn], user_id2...}\n",
    "    K: Ｋ表示的是相似商品的数量，为每个用户交互的每个商品都选择其最相思的K个商品\n",
    "    N: N表示的是给用户推荐的商品数量，给每个用户推荐相似度最大的N个商品\n",
    "    '''\n",
    "\n",
    "    # 建立user->item的倒排表\n",
    "    # 倒排表的格式为: {user_id1: [item_id1, item_id2,...,item_idn], user_id2: ...} 也就是每个用户交互过的所有商品集合\n",
    "    # 由于输入的训练数据trn_user_items,本身就是这中格式的，所以这里不需要进行额外的计算\n",
    "    \n",
    "\n",
    "    # 计算商品协同过滤矩阵\n",
    "    # 即利用user-items倒排表统计商品与商品之间被共同的用户交互的次数\n",
    "    # 商品协同过滤矩阵的表示形式为：sim = {item_id1: {item_id２: num1}, item_id３: {item_id４: num２}, ...}\n",
    "    # 商品协同过滤矩阵是一个双层的字典，用来表示商品之间共同交互的用户数量\n",
    "    # 在计算商品协同过滤矩阵的同时还需要记录每个商品被多少不同用户交互的次数，其表示形式为: num = {item_id1：num1, item_id２:num2, ...}\n",
    "    sim = {}\n",
    "    num = {}\n",
    "    print('构建相似性矩阵．．．')\n",
    "    for uid, items in tqdm(trn_user_items.items()):\n",
    "        for i in items:    \n",
    "            if i not in num:\n",
    "                num[i] = 0\n",
    "            num[i] += 1\n",
    "            if i not in sim:\n",
    "                sim[i] = {}\n",
    "            for j in items:\n",
    "                if j not in sim[i]:\n",
    "                    sim[i][j] = 0\n",
    "                if i != j:\n",
    "                    sim[i][j] += 1\n",
    "    \n",
    "    # 计算物品的相似度矩阵\n",
    "    # 商品协同过滤矩阵其实相当于是余弦相似度的分子部分,还需要除以分母,即两个商品被交互的用户数量的乘积\n",
    "    # 两个商品被交互的用户数量就是上面统计的num字典\n",
    "    print('计算协同过滤矩阵．．．')\n",
    "    for i, items in tqdm(sim.items()):\n",
    "        for j, score in items.items():\n",
    "            if i != j:\n",
    "                sim[i][j] = score / math.sqrt(num[i] * num[j])\n",
    "    \n",
    "\n",
    "    # 对验证数据中的每个用户进行TopN推荐\n",
    "    # 在对用户进行推荐之前需要先通过商品相似度矩阵得到当前用户交互过的商品最相思的前K个商品，\n",
    "    # 然后对这K个用户交互的商品中除当前测试用户训练集中交互过的商品以外的商品计算最终的相似度分数\n",
    "    # 最终推荐的候选商品的相似度分数是由多个相似商品对该商品分数的一个累加和\n",
    "    items_rank = {}\n",
    "    print('给用户进行推荐．．．')\n",
    "    for uid, _ in tqdm(val_user_items.items()):\n",
    "        items_rank[uid] = {} # 存储用户候选的推荐商品\n",
    "        for hist_item in trn_user_items[uid]: # 遍历该用户历史喜欢的商品，用来下面寻找其相似的商品\n",
    "            for item, score in sorted(sim[hist_item].items(), key=lambda x: x[1], reverse=True)[:K]:\n",
    "                if item not in trn_user_items[uid]: # 进行推荐的商品一定不能在历史喜欢商品中出现\n",
    "                    if item not in items_rank[uid]:\n",
    "                        items_rank[uid][item] = 0\n",
    "                    items_rank[uid][item] += score\n",
    "    \n",
    "    print('为每个用户筛选出相似度分数最高的Ｎ个商品...')\n",
    "    items_rank = {k: sorted(v.items(), key=lambda x: x[1], reverse=True)[:N] for k, v in items_rank.items()}\n",
    "    items_rank = {k: set([x[0] for x in v]) for k, v in items_rank.items()}\n",
    "    return items_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "958c8ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "构建相似性矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6040/6040 [01:02<00:00, 97.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "计算协同过滤矩阵．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3681/3681 [00:03<00:00, 944.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "给用户进行推荐．．．\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6033/6033 [14:40<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "为每个用户筛选出相似度分数最高的Ｎ个商品...\n"
     ]
    }
   ],
   "source": [
    "rec_items = Item_CF(trn_user_items, val_user_items, 80, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e275dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 8.63\n",
      "precision 28.61\n",
      "coverage 13.64\n",
      "Popularity 7.324\n"
     ]
    }
   ],
   "source": [
    "rec_eval(rec_items, val_user_items, trn_user_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407196a3",
   "metadata": {},
   "source": [
    "### FM with Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46ae0d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-01 16:39:02.090136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19d4c5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense特征取对数　　sparse特征进行类别编码\n",
    "def process_feat(data, dense_feats, sparse_feats):\n",
    "    df = data.copy()\n",
    "    # dense\n",
    "    df_dense = df[dense_feats].fillna(0.0)\n",
    "    for f in tqdm(dense_feats):\n",
    "        df_dense[f] = df_dense[f].apply(lambda x: np.log(1 + x) if x > -1 else -1)\n",
    "\n",
    "    # sparse\n",
    "    df_sparse = df[sparse_feats].fillna('-1')\n",
    "    for f in tqdm(sparse_feats):\n",
    "        lbe = LabelEncoder()\n",
    "        df_sparse[f] = lbe.fit_transform(df_sparse[f])\n",
    "\n",
    "    df_sparse_arr = []\n",
    "    for f in tqdm(sparse_feats):\n",
    "        data_new = pd.get_dummies(df_sparse.loc[:, f].values)\n",
    "        data_new.columns = [f + \"_{}\".format(i) for i in range(data_new.shape[1])]\n",
    "        df_sparse_arr.append(data_new)\n",
    "\n",
    "    df_new = pd.concat([df_dense] + df_sparse_arr, axis=1)\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a45e275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FM 特征组合层\n",
    "class crossLayer(layers.Layer):\n",
    "    def __init__(self, input_dim, output_dim=10, **kwargs):\n",
    "        super(crossLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        # 定义交叉特征的权重\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=(self.input_dim, self.output_dim),\n",
    "                                      initializer='glorot_uniform',\n",
    "                                      trainable=True)\n",
    "\n",
    "    def call(self, x):  # 对照上述公式中的二次项优化公式一起理解\n",
    "        a = K.pow(K.dot(x, self.kernel), 2)\n",
    "        b = K.dot(K.pow(x, 2), K.pow(self.kernel, 2))\n",
    "        return 0.5 * K.mean(a - b, 1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dac7b4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义FM模型\n",
    "def FM(feature_dim):\n",
    "    inputs = Input(shape=(feature_dim,))\n",
    "\n",
    "    # 一阶特征\n",
    "    linear = Dense(units=1,\n",
    "                   kernel_regularizer=regularizers.l2(0.01),\n",
    "                   bias_regularizer=regularizers.l2(0.01))(inputs)\n",
    "\n",
    "    # 二阶特征\n",
    "    cross = crossLayer(feature_dim)(inputs)\n",
    "    add = Add()([linear, cross])  # 将一阶特征与二阶特征相加构建FM模型\n",
    "\n",
    "    pred = Dense(units=1, activation=\"sigmoid\")(add)\n",
    "    model = Model(inputs=inputs, outputs=pred)\n",
    "\n",
    "    model.summary()\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.Adam(),\n",
    "                  metrics=['binary_accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d8e7872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "print('loading data...')\n",
    "data = pd.read_csv('../data/kaggle_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2328a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense 特征开头是I，sparse特征开头是C，Label是标签\n",
    "cols = data.columns.values\n",
    "dense_feats = [f for f in cols if f[0] == 'I']\n",
    "sparse_feats = [f for f in cols if f[0] == 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe545da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 336.43it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 1096.34it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 219.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# 对dense数据和sparse数据分别处理\n",
    "print('processing features')\n",
    "feats = process_feat(data, dense_feats, sparse_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "235873c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练和验证数据\n",
    "x_trn, x_tst, y_trn, y_tst = train_test_split(feats, data['Label'], test_size=0.2, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a456991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 11007)]              0         []                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1)                    11008     ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " cross_layer (crossLayer)    (None, 1)                    110070    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 1)                    0         ['dense[0][0]',               \n",
      "                                                                     'cross_layer[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 1)                    2         ['add[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 121080 (472.97 KB)\n",
      "Trainable params: 121080 (472.97 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 定义模型\n",
    "model = FM(feats.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c7422609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 36ms/step - loss: 0.6126 - binary_accuracy: 0.7670 - val_loss: 0.5083 - val_binary_accuracy: 0.8344\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.5234 - binary_accuracy: 0.7803 - val_loss: 0.4562 - val_binary_accuracy: 0.8344\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4955 - binary_accuracy: 0.7803 - val_loss: 0.4440 - val_binary_accuracy: 0.8344\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4694 - binary_accuracy: 0.7803 - val_loss: 0.4431 - val_binary_accuracy: 0.8344\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 14ms/step - loss: 0.4380 - binary_accuracy: 0.7991 - val_loss: 0.4497 - val_binary_accuracy: 0.8438\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.4033 - binary_accuracy: 0.8303 - val_loss: 0.4372 - val_binary_accuracy: 0.8438\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 16ms/step - loss: 0.3671 - binary_accuracy: 0.8483 - val_loss: 0.4439 - val_binary_accuracy: 0.8375\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.3294 - binary_accuracy: 0.8819 - val_loss: 0.4454 - val_binary_accuracy: 0.8219\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2933 - binary_accuracy: 0.9070 - val_loss: 0.4523 - val_binary_accuracy: 0.8094\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 15ms/step - loss: 0.2572 - binary_accuracy: 0.9249 - val_loss: 0.4545 - val_binary_accuracy: 0.8094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc1b8ce3e80>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练模型\n",
    "model.fit(x_trn, y_trn, epochs=10, batch_size=128, validation_data=(x_tst, y_tst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06124a1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
