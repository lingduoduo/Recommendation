{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba0a43b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f02936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d29122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161ed8ac",
   "metadata": {},
   "source": [
    "#### Preparing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94625c51",
   "metadata": {},
   "source": [
    "leverage the data generation utility in this TensorFlow Lite On-device Recommendation reference app."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde10738",
   "metadata": {},
   "source": [
    "MovieLens 1M data contains ratings.dat (columns: UserID, MovieID, Rating, Timestamp), and movies.dat (columns: MovieID, Title, Genres). The example generation script download the 1M dataset, takes both files, only keep ratings higher than 2, form user movie interaction timelines, sample activities as labels and 10 previous user activities as the context for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d167fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-03-11 14:28:48--  https://raw.githubusercontent.com/tensorflow/examples/master/lite/examples/recommendation/ml/data/example_generation_movielens.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 18040 (18K) [text/plain]\n",
      "Saving to: ‘example_generation_movielens.py’\n",
      "\n",
      "example_generation_ 100%[===================>]  17.62K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2022-03-11 14:28:48 (9.75 MB/s) - ‘example_generation_movielens.py’ saved [18040/18040]\n",
      "\n",
      "I0311 14:28:52.488744 4430112256 example_generation_movielens.py:460] Downloading and extracting data.\n",
      "Downloading data from http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
      "5922816/5917549 [==============================] - 0s 0us/step\n",
      "I0311 14:28:53.269633 4430112256 example_generation_movielens.py:406] Reading data to dataframes.\n",
      "/Users/lhuang/Git/Deep-recommender-sandbox/notebooks/Recommenders/example_generation_movielens.py:136: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  encoding=\"unicode_escape\")  # May contain unicode. Need to escape.\n",
      "/Users/lhuang/Git/Deep-recommender-sandbox/notebooks/Recommenders/example_generation_movielens.py:144: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  encoding=\"unicode_escape\")  # May contain unicode. Need to escape.\n",
      "I0311 14:28:57.575231 4430112256 example_generation_movielens.py:408] Generating movie rating user timelines.\n",
      "I0311 14:29:00.993018 4430112256 example_generation_movielens.py:410] Generating train and test examples.\n",
      "6040/6040 [==============================] - 109s 18ms/step\n",
      "I0311 14:30:51.337964 4430112256 example_generation_movielens.py:421] Writing generated training examples.\n",
      "844195/844195 [==============================] - 19s 23us/step\n",
      "I0311 14:31:10.499083 4430112256 example_generation_movielens.py:424] Writing generated testing examples.\n",
      "93799/93799 [==============================] - 2s 23us/step\n",
      "I0311 14:31:17.726829 4430112256 example_generation_movielens.py:473] Generated dataset: {'train_size': 844195, 'test_size': 93799, 'train_file': 'data/examples/train_movielens_1m.tfrecord', 'test_file': 'data/examples/test_movielens_1m.tfrecord'}\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/tensorflow/examples/master/lite/examples/recommendation/ml/data/example_generation_movielens.py\n",
    "!python -m example_generation_movielens  --data_dir=data/raw  --output_dir={{data/examples}}  --min_timeline_length=3  --max_context_length=10  --max_context_movie_genre_length=10  --min_rating=2  --train_data_fraction=0.9  --build_vocabs=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01953839",
   "metadata": {},
   "source": [
    "Here is a sample of the generated dataset.\n",
    "\n",
    "```0 : {\n",
    "  features: {\n",
    "    feature: {\n",
    "      key  : \"context_movie_id\"\n",
    "      value: { int64_list: { value: [ 1124, 2240, 3251, ..., 1268 ] } }\n",
    "    }\n",
    "    feature: {\n",
    "      key  : \"context_movie_rating\"\n",
    "      value: { float_list: {value: [ 3.0, 3.0, 4.0, ..., 3.0 ] } }\n",
    "    }\n",
    "    feature: {\n",
    "      key  : \"context_movie_year\"\n",
    "      value: { int64_list: { value: [ 1981, 1980, 1985, ..., 1990 ] } }\n",
    "    }\n",
    "    feature: {\n",
    "      key  : \"context_movie_genre\"\n",
    "      value: { bytes_list: { value: [ \"Drama\", \"Drama\", \"Mystery\", ..., \"UNK\" ] } }\n",
    "    }\n",
    "    feature: {\n",
    "      key  : \"label_movie_id\"\n",
    "      value: { int64_list: { value: [ 3252 ] }  }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b7e1726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _parse_function at 0x7fc2cc450e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _parse_function at 0x7fc2cc450e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc2cc450a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc2cc450a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc2d8c56e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc2d8c56e60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "{'context_movie_id': array([b'1343', b'1111', b'1914', b'2435', b'2108', b'3147', b'112',\n",
      "       b'1357', b'357', b'440'], dtype=object),\n",
      " 'label_movie_id': array([b'1834'], dtype=object)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 14:33:48.478799: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-11 14:33:48.574778: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "train_filename = \"./data/examples/train_movielens_1m.tfrecord\"\n",
    "train = tf.data.TFRecordDataset(train_filename)\n",
    "\n",
    "test_filename = \"./data/examples/test_movielens_1m.tfrecord\"\n",
    "test = tf.data.TFRecordDataset(test_filename)\n",
    "\n",
    "feature_description = {\n",
    "    'context_movie_id': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(0, 10)),\n",
    "    'context_movie_rating': tf.io.FixedLenFeature([10], tf.float32, default_value=np.repeat(0, 10)),\n",
    "    'context_movie_year': tf.io.FixedLenFeature([10], tf.int64, default_value=np.repeat(1980, 10)),\n",
    "    'context_movie_genre': tf.io.FixedLenFeature([10], tf.string, default_value=np.repeat(\"Drama\", 10)),\n",
    "    'label_movie_id': tf.io.FixedLenFeature([1], tf.int64, default_value=0),\n",
    "}\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, feature_description)\n",
    "\n",
    "train_ds = train.map(_parse_function).map(lambda x: {\n",
    "    \"context_movie_id\": tf.strings.as_string(x[\"context_movie_id\"]),\n",
    "    \"label_movie_id\": tf.strings.as_string(x[\"label_movie_id\"])\n",
    "})\n",
    "\n",
    "test_ds = test.map(_parse_function).map(lambda x: {\n",
    "    \"context_movie_id\": tf.strings.as_string(x[\"context_movie_id\"]),\n",
    "    \"label_movie_id\": tf.strings.as_string(x[\"label_movie_id\"])\n",
    "})\n",
    "\n",
    "for x in train_ds.take(1).as_numpy_iterator():\n",
    "    pprint.pprint(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e590251c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-11 14:36:22.577624: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"Not found: Could not locate the credentials file.\". Retrieving token from GCE failed with \"Failed precondition: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 5.64 MiB (download: 5.64 MiB, generated: 351.12 KiB, total: 5.99 MiB) to /Users/lhuang/tensorflow_datasets/movielens/1m-movies/0.1.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdcbd30cfce4e3dbe617925706b9ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08cb7012b8754beaa71439c99d9c7e07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f9c3b04c724298b202cf961ffa0fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...:   0%|          | 0/3883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling movielens-train.tfrecord...:   0%|          | 0/3883 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset movielens downloaded and prepared to /Users/lhuang/tensorflow_datasets/movielens/1m-movies/0.1.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc2b88e7170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function <lambda> at 0x7fc2b88e7170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fc2b88e7170> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "movies = tfds.load(\"movielens/1m-movies\", split='train')\n",
    "movies = movies.map(lambda x: x[\"movie_id\"])\n",
    "movie_ids = movies.batch(1_000)\n",
    "unique_movie_ids = np.unique(np.concatenate(list(movie_ids)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f5a3f",
   "metadata": {},
   "source": [
    "### Implementing a sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011eb48",
   "metadata": {},
   "source": [
    "In our basic retrieval tutorial, we use one query tower for the user, and the candidate tow for the candidate movie. However, the two-tower architecture is generalizble and not limited to <user,item> pair. You can also use it to do item-to-item recommendation as we note in the basic retrieval tutorial.\n",
    "\n",
    "Here we are still going to use the two-tower architecture. Specificially, we use the query tower with a Gated Recurrent Unit (GRU) layer to encode the sequence of historical movies, and keep the same candidate tower for the candidate movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e3248aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dimension = 32\n",
    "\n",
    "query_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_ids, mask_token=None),\n",
    "    tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dimension), \n",
    "    tf.keras.layers.GRU(embedding_dimension),\n",
    "])\n",
    "\n",
    "candidate_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.StringLookup(\n",
    "      vocabulary=unique_movie_ids, mask_token=None),\n",
    "  tf.keras.layers.Embedding(len(unique_movie_ids) + 1, embedding_dimension)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbebc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(candidate_model)\n",
    ")\n",
    "\n",
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics\n",
    ")\n",
    "\n",
    "class Model(tfrs.Model):\n",
    "\n",
    "    def __init__(self, query_model, candidate_model):\n",
    "        super().__init__()\n",
    "        self._query_model = query_model\n",
    "        self._candidate_model = candidate_model\n",
    "\n",
    "        self._task = task\n",
    "\n",
    "    def compute_loss(self, features, training=False):\n",
    "        watch_history = features[\"context_movie_id\"]\n",
    "        watch_next_label = features[\"label_movie_id\"]\n",
    "\n",
    "        query_embedding = self._query_model(watch_history)       \n",
    "        candidate_embedding = self._candidate_model(watch_next_label)\n",
    "        \n",
    "        return self._task(query_embedding, candidate_embedding, compute_metrics=not training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c963e",
   "metadata": {},
   "source": [
    "### Fitting and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d07dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(query_model, candidate_model)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e0a6001",
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train_ds.shuffle(10_000).batch(12800).cache()\n",
    "cached_test = test_ds.batch(2560).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7270859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc2d8f02200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc2d8f02200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7fc2d8f02200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fc2b88b8210>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fc2b88b8210>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Retrieval.call of <tensorflow_recommenders.tasks.retrieval.Retrieval object at 0x7fc2b88b8210>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "67/67 [==============================] - 67s 971ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 107930.5723 - regularization_loss: 0.0000e+00 - total_loss: 107930.5723\n",
      "Epoch 2/3\n",
      "67/67 [==============================] - 56s 832ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 101372.3996 - regularization_loss: 0.0000e+00 - total_loss: 101372.3996\n",
      "Epoch 3/3\n",
      "67/67 [==============================] - 59s 888ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_5_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_10_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_50_categorical_accuracy: 0.0000e+00 - factorized_top_k/top_100_categorical_accuracy: 0.0000e+00 - loss: 99644.8464 - regularization_loss: 0.0000e+00 - total_loss: 99644.8464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc2b88ba290>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3eafb3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc2992c1710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc2992c1710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7fc2992c1710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fc2d8ec6e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fc2d8ec6e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Streaming.call of <tensorflow_recommenders.layers.factorized_top_k.Streaming object at 0x7fc2d8ec6e50>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc2887e4950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc2887e4950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.enumerate_rows at 0x7fc2887e4950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc288e49200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc288e49200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_scores at 0x7fc288e49200> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow2.5/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lhuang/opt/miniconda3/envs/tensorflow2.5/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc288e493b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc288e493b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Streaming.call.<locals>.top_k at 0x7fc288e493b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "37/37 [==============================] - 15s 384ms/step - factorized_top_k/top_1_categorical_accuracy: 0.0146 - factorized_top_k/top_5_categorical_accuracy: 0.0761 - factorized_top_k/top_10_categorical_accuracy: 0.1334 - factorized_top_k/top_50_categorical_accuracy: 0.3696 - factorized_top_k/top_100_categorical_accuracy: 0.5020 - loss: 15518.2761 - regularization_loss: 0.0000e+00 - total_loss: 15518.2761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'factorized_top_k/top_1_categorical_accuracy': 0.014616360887885094,\n",
       " 'factorized_top_k/top_5_categorical_accuracy': 0.07607757300138474,\n",
       " 'factorized_top_k/top_10_categorical_accuracy': 0.1333596259355545,\n",
       " 'factorized_top_k/top_50_categorical_accuracy': 0.369588166475296,\n",
       " 'factorized_top_k/top_100_categorical_accuracy': 0.5020096302032471,\n",
       " 'loss': 9388.5966796875,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 9388.5966796875}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399f3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
